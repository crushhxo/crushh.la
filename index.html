<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>crushh.la</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    body {
      margin: 0;
      padding: 0;
      background: #ffffff;
      color: #111111;
      font-family: -apple-system, BlinkMacSystemFont, "Helvetica Neue", Arial, sans-serif;
      min-height: 100vh;
      overflow-x: hidden;
      overflow-y: auto;
      cursor: default;
    }

    .center-shell {
      position: relative;
      min-height: 100vh;
      display: flex;
      align-items: center;
      justify-content: center;
      text-align: center;
      box-sizing: border-box;
      padding: 40px 20px 32px;
      perspective: 1200px;
      transform-style: preserve-3d;
    }

    @media (max-width: 430px) {
      .center-shell {
        padding: 12px 12px 12px;
        min-height: 100vh;
        align-items: flex-start;
        padding-top: 12px;
        transform: scale(0.9);
        transform-origin: top center;
      }

      .logo-shell {
        margin-bottom: 4px; /* Uniform spacing - match drum-header margin-bottom */
      }

      .synth {
        margin-top: 4px; /* Uniform spacing */
      }

      .step-indicator {
        margin-top: 4px; /* Uniform spacing */
        gap: 3px;
      }

      .seq-controls {
        margin-top: 4px; /* Uniform spacing */
      }

      .transport {
        margin-top: 4px; /* Uniform spacing */
        gap: 4px;
      }

      .drums {
        margin-top: 4px; /* Uniform spacing */
        row-gap: 10px;
        column-gap: 10px;
      }

      .ringer-note {
        margin-top: 4px; /* Uniform spacing */
        margin-bottom: 4px; /* Uniform spacing */
        font-size: 10px;
      }

      .email {
        margin-top: 4px; /* Uniform spacing */
      }
    }

    .container {
      max-width: 620px;
      width: 100%;
    }

    /* outer shell: handles fade + 3D crash */
    .logo-shell {
      display: flex;
      justify-content: center;
      margin: 0 auto 12px auto; /* Match drum sequencer row-gap spacing */
      opacity: 0;
      transform: translateZ(0);
      will-change: transform, opacity, filter;
    }

    /* inner img: only for flicker */
    .logo {
      width: 100%;
      max-width: 260px; /* match piano width */
      height: auto;
      display: block;
      opacity: 1;
      transform: translate(0, 0) skewX(0deg);
      will-change: transform, opacity, filter;
    }

    .logo-shell.normal-in {
      animation: logoInitialFade 2.2s ease forwards;
      animation-delay: 0.4s;
    }

    .logo-shell.crash-in {
      transform-origin: center center;
      animation: logoCrash 0.8s cubic-bezier(0.2, 0.8, 0.25, 1.1) forwards;
    }

    @keyframes logoInitialFade {
      0%   { opacity: 0; transform: translateY(4px); }
      100% { opacity: 1; transform: translateY(0); }
    }

    @keyframes logoCrash {
      0% {
        opacity: 0;
        transform: translateZ(950px) scale(2.9) rotateX(16deg);
        filter: blur(12px) contrast(1.35);
      }
      30% {
        opacity: 1;
        transform: translateZ(200px) scale(1.6) rotateX(8deg);
        filter: blur(6px) contrast(1.25);
      }
      55% {
        opacity: 1;
        transform: translateZ(0) scale(1.04) rotateX(0deg);
        filter: blur(1px) contrast(1.12);
      }
      78% {
        transform: translateZ(-28px) scale(0.985);
        filter: blur(0.4px) contrast(1.04);
      }
      100% {
        opacity: 1;
        transform: translateZ(0) scale(1);
        filter: none;
      }
    }

    /* synth piano layout */
    .synth {
      margin-top: 6px; /* Reduced spacing to shift elements up */
      position: relative;
      display: flex;
      justify-content: center;
      align-items: center;
    }

    .scale-selectors {
      position: absolute;
      left: calc(50% - 130px - 60px); /* Position to the left of centered piano (piano is 260px wide, centered at 50%, so left edge is at 50% - 130px, then subtract selector width + small gap) */
      display: flex;
      flex-direction: column;
      gap: 6px;
      align-items: flex-start;
    }

    .scale-selector {
      font-size: 10px;
      padding: 4px 8px;
      border-radius: 12px;
      border: 1px solid rgba(0, 0, 0, 0.35);
      background: rgba(0, 0, 0, 0.03);
      color: #111111;
      cursor: pointer;
      letter-spacing: 0.08em;
      transition: background 120ms ease, border-color 120ms ease;
      min-width: 50px;
      text-align: center;
    }

    .scale-selector:hover {
      background: rgba(0, 0, 0, 0.08);
    }

    .scale-selector:focus {
      outline: none;
      border-color: rgba(0, 0, 0, 0.5);
    }

    .octave-controls {
      position: absolute;
      left: calc(50% + 130px + 8px); /* Position to the right of centered piano (piano is 260px wide, centered at 50%, so right edge is at 50% + 130px, then add small gap) */
      display: flex;
      flex-direction: column;
      gap: 6px;
      align-items: flex-start;
    }

    .octave-button {
      font-size: 10px;
      padding: 4px 8px;
      border-radius: 12px;
      border: 1px solid rgba(0, 0, 0, 0.35);
      background: rgba(0, 0, 0, 0.03);
      color: #111111;
      cursor: pointer;
      letter-spacing: 0.08em;
      transition: background 120ms ease, border-color 120ms ease;
      min-width: 50px;
      text-align: center;
      font-family: -apple-system, BlinkMacSystemFont, "Helvetica Neue", Arial, sans-serif;
    }

    .octave-button:hover {
      background: rgba(0, 0, 0, 0.08);
    }

    .octave-button:active {
      transform: translateY(1px);
    }

    .octave-button:focus {
      outline: none;
      border-color: rgba(0, 0, 0, 0.5);
    }

    .mode-selectors {
      display: flex;
      justify-content: center;
      align-items: center;
      gap: 6px;
      margin: 8px 0;
    }
    .mode-selector {
      font-size: 10px;
      padding: 4px 8px;
      border-radius: 12px;
      border: 1px solid rgba(0, 0, 0, 0.35);
      background: rgba(0, 0, 0, 0.03);
      color: #111111;
      cursor: pointer;
      letter-spacing: 0.08em;
      transition: background 120ms ease, border-color 120ms ease;
      min-width: 60px;
      text-align: center;
      font-family: -apple-system, BlinkMacSystemFont, "Helvetica Neue", Arial, sans-serif;
    }
    .mode-selector:hover {
      background: rgba(0, 0, 0, 0.08);
    }
    .mode-selector:focus {
      outline: none;
      border-color: rgba(0, 0, 0, 0.5);
    }
    .arp-mode-selector {
      display: none;
    }
    .mode-selectors.show-arp .arp-mode-selector {
      display: block;
    }
    .arp-latch-button {
      font-size: 10px;
      text-transform: lowercase;
      padding: 4px 8px;
      border-radius: 12px;
      border: 1px solid rgba(0, 0, 0, 0.35);
      background: rgba(0, 0, 0, 0.03);
      color: #111111;
      cursor: pointer;
      letter-spacing: 0.08em;
      transition: background 120ms ease, border-color 120ms ease, color 120ms ease, transform 80ms ease;
      min-width: 60px;
      text-align: center;
      font-family: -apple-system, BlinkMacSystemFont, "Helvetica Neue", Arial, sans-serif;
      display: none;
    }
    .mode-selectors.show-arp .arp-latch-button {
      display: block;
    }
    .arp-latch-button:hover {
      background: rgba(0, 0, 0, 0.08);
    }
    .arp-latch-button.active {
      background: #111111;
      color: #f7f7f7;
      border-color: #111111;
      transform: translateY(1px);
    }

    .piano {
      position: relative;
      width: 260px;
      height: 110px;
      margin: 0 auto 4px auto;
      display: block;
      animation: pianoFloat 6s ease-in-out infinite alternate;
    }

    @keyframes pianoFloat {
      0% { transform: translateY(0); }
      100% { transform: translateY(-3px); }
    }

    .white-keys {
      position: absolute;
      inset: 0;
      display: flex;
      gap: 0;
    }

    .black-keys {
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      height: 65%;
      pointer-events: none;
    }

    .key {
      border-radius: 3px;
      cursor: pointer;
      user-select: none;
      position: relative;
      overflow: hidden;
      transition:
        background 90ms ease,
        transform 90ms ease,
        filter 90ms ease,
        border-color 90ms ease;
    }

    .key::after {
      content: "";
      position: absolute;
      inset: 0;
      pointer-events: none;
      background-image:
        radial-gradient(circle at 10% 20%, rgba(0,0,0,0.05) 0, transparent 40%),
        radial-gradient(circle at 80% 60%, rgba(0,0,0,0.04) 0, transparent 45%),
        radial-gradient(circle at 30% 80%, rgba(0,0,0,0.045) 0, transparent 50%);
      mix-blend-mode: multiply;
      opacity: 0.4;
    }

    .key.white {
      flex: 1;
      height: 100%;
      border: 1px solid #b9b9b9;
      background: linear-gradient(to bottom, #d7d7d7 0%, #c5c5c5 100%);
    }

    .key.black {
      position: absolute;
      width: 22px;
      height: 70%;
      border: 1px solid #747272;
      background: linear-gradient(to bottom, #9c9a97 0%, #7c7a77 100%);
      z-index: 2;
      pointer-events: auto;
    }

    .key.black.csharp { left: 22px; }
    .key.black.dsharp { left: 54px; }
    .key.black.fsharp { left: 117px; }
    .key.black.gsharp { left: 149px; }
    .key.black.asharp { left: 181px; }

    .key:active,
    .key.is-down {
      transform: translateY(1px);
      filter: brightness(0.94) contrast(1.03);
      border-color: #9c9c9c;
    }

    /* transport + sequencer */
    .step-indicator {
      margin-top: 4px;
      display: flex;
      justify-content: center;
      gap: 4px;
      width: 260px; /* match piano width */
      margin-left: auto;
      margin-right: auto;
    }

    .step-dot {
      width: 10px;
      height: 10px;
      border-radius: 2px;
      box-sizing: border-box;
      border: 1px solid #111111;
      background: #ffffff;
      transition: background 80ms ease, transform 80ms ease;
      flex: 1; /* distribute evenly to fill 260px width */
    }

    .step-dot.downbeat {
      background: #e0e0e0; /* darker grey for downbeats */
    }

    .step-dot.active {
      background: #111111;
      transform: translateY(1px);
    }

    .step-dot.downbeat.active {
      background: #111111;
      transform: translateY(1px);
    }

    .seq-controls {
      margin-top: 4px;
      display: flex;
      justify-content: center;
    }

    .seq-button {
      font-size: 10px;
      text-transform: lowercase;
      padding: 3px 12px;
      border-radius: 999px;
      border: 1px solid rgba(0, 0, 0, 0.35);
      background: rgba(0, 0, 0, 0.03);
      color: #111111;
      cursor: pointer;
      letter-spacing: 0.12em;
      transition: background 120ms ease, border-color 120ms ease, color 120ms ease, transform 80ms ease;
    }

    .seq-button.recording {
      background: #b80000;
      border-color: #b80000;
      color: #f7f7f7;
      transform: translateY(1px);
    }

    .seq-button.looping {
      background: #111111;
      border-color: #111111;
      color: #f7f7f7;
    }

    .transport {
      margin-top: 4px;
      display: flex;
      justify-content: center;
      gap: 6px;
      position: relative;
    }

    .transport-button {
      font-size: 11px;
      text-transform: lowercase;
      padding: 4px 10px;
      border-radius: 999px;
      border: 1px solid rgba(0, 0, 0, 0.35);
      background: rgba(0, 0, 0, 0.03);
      color: #111111;
      cursor: pointer;
      letter-spacing: 0.1em;
      transition: background 120ms ease, border-color 120ms ease, color 120ms ease, transform 80ms ease;
    }

    .transport-button:hover {
      background: rgba(0, 0, 0, 0.06);
    }

    .transport-button.active {
      background: #111111;
      color: #f7f7f7;
      border-color: #111111;
      transform: translateY(1px);
    }

    .tooltip-button {
      position: absolute;
      right: calc(50% - 130px); /* Align with right edge of drum sequencers (260px container centered) */
      font-size: 11px;
      width: 24px;
      height: 24px;
      border-radius: 50%;
      border: 1px solid rgba(0, 0, 0, 0.35);
      background: rgba(0, 0, 0, 0.03);
      color: #111111;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: background 120ms ease, border-color 120ms ease, color 120ms ease, transform 80ms ease;
      font-weight: normal;
      line-height: 1;
    }

    .tooltip-button:hover {
      background: rgba(0, 0, 0, 0.06);
    }

    .tooltip-dialogue {
      position: fixed;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      background: #ffffff;
      border: 1px solid rgba(0, 0, 0, 0.2);
      border-radius: 8px;
      padding: 20px;
      max-width: 320px;
      width: calc(100% - 40px);
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
      z-index: 1000;
      font-size: 12px;
      line-height: 1.6;
      color: #111111;
      display: none;
    }

    .tooltip-dialogue.active {
      display: block;
    }

    .tooltip-overlay {
      position: fixed;
      top: 0;
      left: 0;
      right: 0;
      bottom: 0;
      background: rgba(0, 0, 0, 0.3);
      z-index: 999;
      display: none;
    }

    .tooltip-overlay.active {
      display: block;
    }

    .tooltip-close {
      position: absolute;
      top: 8px;
      right: 8px;
      background: none;
      border: none;
      font-size: 18px;
      color: #111111;
      cursor: pointer;
      width: 24px;
      height: 24px;
      display: flex;
      align-items: center;
      justify-content: center;
      opacity: 0.6;
      transition: opacity 120ms ease;
    }

    .tooltip-close:hover {
      opacity: 1;
    }

    @media (max-width: 430px) {
      .tooltip-button {
        right: calc(50% - 130px);
      }

      .tooltip-dialogue {
        max-width: 280px;
        padding: 16px;
        font-size: 11px;
      }

      .keyboard-mode-info {
        display: none;
      }
    }

    /* drums */
    .drums {
      margin-top: 16px;
      max-width: 260px; /* matches piano width */
      margin-left: auto;
      margin-right: auto;
      display: grid;
      grid-template-columns: repeat(2, minmax(0, 1fr));
      column-gap: 12px;
      row-gap: 12px;
      align-items: flex-start;
      justify-items: center;
    }

    .drum-lane {
      width: 100%;
      position: relative;
    }

    /* Part Mixer */
    .part-mixer {
      grid-column: 2; /* Place in right column */
      grid-row: 3; /* Same row as perc */
      justify-self: end; /* Align to right */
      display: flex;
      gap: 1px;
      justify-content: center;
      align-items: flex-start;
      width: 120px; /* Match drum sequencer width exactly */
      max-width: 120px;
      box-sizing: border-box;
    }

    .mixer-channel {
      display: flex;
      flex-direction: column;
      align-items: center;
      gap: 3px;
      flex: 1 1 0;
      min-width: 0;
      max-width: 100%;
    }

    .mixer-label {
      font-size: 9px;
      text-transform: lowercase;
      color: #111111;
      letter-spacing: 0.05em;
      margin-bottom: 2px;
      height: 12px;
      display: flex;
      align-items: center;
      justify-content: center;
      width: 100%;
      flex-shrink: 0;
    }

    .mixer-slider-container {
      height: 62px; /* Slider height to match total mixer height with perc drum sequencer bottom */
      display: flex;
      align-items: center;
      justify-content: center;
      position: relative;
      width: 100%;
      flex-shrink: 0;
    }

    /* Mixer Slider - Consistent cross-browser styling */
    .mixer-slider {
      /* Use slider-vertical for webkit browsers, writing-mode for others */
      -webkit-appearance: slider-vertical;
      appearance: slider-vertical;
      writing-mode: bt-lr; /* Fallback for non-webkit */
      
      /* Dimensions */
      width: 5px;
      height: 62px;
      
      /* Reset */
      background: transparent;
      border: none;
      outline: none;
      margin: 0;
      padding: 0;
      cursor: pointer;
      
      /* Prevent tap highlight */
      -webkit-tap-highlight-color: transparent;
    }

    /* Webkit (Chrome, Safari) - Track - consistent styling */
    .mixer-slider::-webkit-slider-track,
    .mixer-slider::-webkit-slider-runnable-track {
      -webkit-appearance: none;
      appearance: none;
      width: 5px;
      height: 62px;
      background: #e0e0e0;
      border-radius: 2.5px;
      border: none;
    }

    /* Webkit (Chrome, Safari) - Thumb - consistent styling */
    .mixer-slider::-webkit-slider-thumb {
      -webkit-appearance: none;
      appearance: none;
      width: 5px;
      height: 16px;
      background: #ffffff;
      border: 1px solid #979797;
      border-radius: 2.5px;
      cursor: pointer;
      margin: 0;
      padding: 0;
    }

    /* Firefox - Track - consistent styling */
    .mixer-slider::-moz-range-track {
      -moz-appearance: none;
      appearance: none;
      width: 5px;
      height: 62px;
      background: #e0e0e0;
      border-radius: 2.5px;
      border: none;
    }

    /* Firefox - Thumb - consistent styling */
    .mixer-slider::-moz-range-thumb {
      -moz-appearance: none;
      appearance: none;
      width: 5px;
      height: 16px;
      background: #ffffff;
      border: 1px solid #979797;
      border-radius: 2.5px;
      cursor: pointer;
      margin: 0;
      padding: 0;
    }

    .mixer-mute-button {
      font-size: 10px;
      text-transform: lowercase;
      padding: 0;
      border-radius: 2px; /* Square with slight rounding */
      border: 1px solid rgba(0, 0, 0, 0.25);
      background: rgba(0, 0, 0, 0.02);
      color: #111111;
      cursor: pointer;
      letter-spacing: 0.08em;
      transition: background 120ms ease, border-color 120ms ease, color 120ms ease, transform 80ms ease;
      width: 16px;
      height: 16px;
      display: flex;
      align-items: center;
      justify-content: center;
      flex-shrink: 0;
    }

    .mixer-mute-button:hover {
      background: rgba(0, 0, 0, 0.05);
    }

    .mixer-mute-button.active {
      background: #111111;
      color: #f7f7f7;
      border-color: #111111;
      transform: translateY(1px);
    }

    .drum-header {
      display: flex;
      justify-content: center;
      align-items: center;
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      width: 120px;
      pointer-events: none;
    }
    
    .drum-header select {
      pointer-events: auto;
    }


    .drum-select {
      font-size: 10px;
      padding: 2px 8px;
      border-radius: 999px;
      border: 1px solid rgba(0, 0, 0, 0.3);
      background: rgba(0, 0, 0, 0.02);
      color: #111111;
      letter-spacing: 0.08em;
      text-transform: none;
      outline: none;
      cursor: pointer;
      flex-shrink: 0;
      min-width: 60px;
    }

    .drum-grid {
      margin: 0 auto;
      display: grid;
      grid-template-columns: repeat(4, minmax(12px, 1fr));
      grid-template-rows: repeat(4, 16px);
      gap: 3px;
      max-width: 120px; /* narrower blocks */
    }

    .drum-cell {
      border-radius: 2px;
      border: 1px solid #979797;
      background: #ffffff;
      box-sizing: border-box;
      cursor: pointer;
      transition: background 90ms ease, border-color 90ms ease, transform 90ms ease;
    }

    .drum-cell.active {
      background: #111111;
      border-color: #111111;
      transform: translateY(1px);
    }

    .ringer-note {
      font-size: 11px;
      font-style: italic;
      color: rgba(0, 0, 0, 0.55);
      margin-top: 4px;
      margin-bottom: 4px;
    }

    .email {
      margin-top: 12px;
    }

    .email a {
      font-size: 16px;
      color: #111111;
      text-decoration: none;
      border-bottom: 1px solid #11111133;
      padding-bottom: 2px;
    }

    .email a:hover {
      opacity: 0.6;
    }

    .cursor-trail {
      position: fixed;
      width: 18px;
      height: 18px;
      border-radius: 50%;
      background: rgba(0, 0, 0, 0.1);
      pointer-events: none;
      transform: translate(-50%, -50%);
      filter: blur(5px);
      animation: trailFade 0.7s ease-out forwards;
      z-index: 10;
    }

    @keyframes trailFade {
      0%   { opacity: 0.55; transform: translate(-50%, -50%) scale(1); }
      100% { opacity: 0;    transform: translate(-50%, -50%) scale(1.7); }
    }

  </style>
</head>
<body>

  <div class="center-shell">
    <div class="container">
      <!-- logo -->
      <div class="logo-shell">
        <img class="logo" src="crushh-logo-rust-tp.png" alt="crushh logo" />
      </div>

      <!-- synth piano -->
      <div class="synth">
        <div class="scale-selectors">
          <select class="scale-selector" id="scale-root">
            <option value="C">C</option>
            <option value="C#">C#</option>
            <option value="D">D</option>
            <option value="D#">D#</option>
            <option value="E">E</option>
            <option value="F">F</option>
            <option value="F#">F#</option>
            <option value="G">G</option>
            <option value="G#">G#</option>
            <option value="A" selected>A</option>
            <option value="A#">A#</option>
            <option value="B">B</option>
          </select>
          <select class="scale-selector" id="scale-mode">
            <option value="major" selected>maj</option>
            <option value="minor">min</option>
          </select>
        </div>
        <div class="octave-controls">
          <button class="octave-button" id="octave-up">↑</button>
          <button class="octave-button" id="octave-down">↓</button>
        </div>
        <div class="piano">
          <div class="white-keys">
            <button class="key white" data-note="C1"></button>
            <button class="key white" data-note="D1"></button>
            <button class="key white" data-note="E1"></button>
            <button class="key white" data-note="F1"></button>
            <button class="key white" data-note="G1"></button>
            <button class="key white" data-note="A1"></button>
            <button class="key white" data-note="B1"></button>
            <button class="key white" data-note="C2"></button>
          </div>
          <div class="black-keys">
            <button class="key black csharp" data-note="C#1"></button>
            <button class="key black dsharp" data-note="D#1"></button>
            <button class="key black fsharp" data-note="F#1"></button>
            <button class="key black gsharp" data-note="G#1"></button>
            <button class="key black asharp" data-note="A#1"></button>
          </div>
        </div>
      </div>

      <div class="mode-selectors" id="mode-selectors">
        <select class="mode-selector" id="synth-mode">
          <option value="bass">bass</option>
          <option value="arp">arp</option>
        </select>
        <select class="mode-selector arp-mode-selector" id="arp-mode">
          <option value="up">up</option>
          <option value="down">down</option>
          <option value="up+1">up +1</option>
          <option value="down-1">down -1</option>
          <option value="rand">rand</option>
          <option value="rand+-1">rand +-1</option>
        </select>
        <button class="arp-latch-button" id="arp-latch">latch</button>
      </div>

      <div class="ringer-note"><em>ringer must be on to play</em></div>

      <!-- 16 quarter-note dots for 4 bars -->
      <div class="step-indicator" id="step-indicator"></div>

      <!-- recorder controls -->
      <div class="seq-controls">
        <button class="seq-button" id="seq-record">rec bass</button>
      </div>

      <!-- transport -->
      <div class="transport">
        <button class="transport-button" id="transport-play">play</button>
        <button class="transport-button" id="transport-stop">stop</button>
        <button class="tooltip-button" id="tooltip-button">?</button>
      </div>

      <!-- drums -->
      <div class="drums">
        <div class="drum-lane" data-part="kick">
          <div class="drum-header">
            <select class="drum-select" data-part="kick">
              <option value="1">kick 1</option>
              <option value="2">kick 2</option>
              <option value="3">kick 3</option>
              <option value="4">kick 4</option>
            </select>
          </div>
          <div class="drum-grid" data-part="kick"></div>
        </div>

        <div class="drum-lane" data-part="snare">
          <div class="drum-header">
            <select class="drum-select" data-part="snare">
              <option value="1">snare 1</option>
              <option value="2">snare 2</option>
              <option value="3">snare 3</option>
              <option value="4">snare 4</option>
            </select>
          </div>
          <div class="drum-grid" data-part="snare"></div>
        </div>

        <div class="drum-lane" data-part="ch">
          <div class="drum-header">
            <select class="drum-select" data-part="ch">
              <option value="1">ch 1</option>
              <option value="2">ch 2</option>
              <option value="3">ch 3</option>
              <option value="4">ch 4</option>
            </select>
          </div>
          <div class="drum-grid" data-part="ch"></div>
        </div>

        <div class="drum-lane" data-part="oh">
          <div class="drum-header">
            <select class="drum-select" data-part="oh">
              <option value="1">oh 1</option>
              <option value="2">oh 2</option>
              <option value="3">oh 3</option>
              <option value="4">oh 4</option>
            </select>
          </div>
          <div class="drum-grid" data-part="oh"></div>
        </div>

        <div class="drum-lane" data-part="perc">
          <div class="drum-header">
            <select class="drum-select" data-part="perc">
              <option value="1">perc 1</option>
              <option value="2">perc 2</option>
              <option value="3">perc 3</option>
              <option value="4">perc 4</option>
            </select>
          </div>
          <div class="drum-grid" data-part="perc"></div>
        </div>

        <!-- Part Mixer -->
        <div class="part-mixer">
          <div class="mixer-channel" data-part="bass">
            <div class="mixer-label">bs</div>
            <div class="mixer-slider-container">
              <input type="range" class="mixer-slider" data-part="bass" orient="vertical" min="0" max="100" value="100">
            </div>
            <button class="mixer-mute-button" data-part="bass">m</button>
          </div>
          <div class="mixer-channel" data-part="arp">
            <div class="mixer-label">arp</div>
            <div class="mixer-slider-container">
              <input type="range" class="mixer-slider" data-part="arp" orient="vertical" min="0" max="100" value="100">
            </div>
            <button class="mixer-mute-button" data-part="arp">m</button>
          </div>
          <div class="mixer-channel" data-part="kick">
            <div class="mixer-label">ki</div>
            <div class="mixer-slider-container">
              <input type="range" class="mixer-slider" data-part="kick" orient="vertical" min="0" max="100" value="100">
            </div>
            <button class="mixer-mute-button" data-part="kick">m</button>
          </div>
          <div class="mixer-channel" data-part="snare">
            <div class="mixer-label">sn</div>
            <div class="mixer-slider-container">
              <input type="range" class="mixer-slider" data-part="snare" orient="vertical" min="0" max="100" value="100">
            </div>
            <button class="mixer-mute-button" data-part="snare">m</button>
          </div>
          <div class="mixer-channel" data-part="ch">
            <div class="mixer-label">ch</div>
            <div class="mixer-slider-container">
              <input type="range" class="mixer-slider" data-part="ch" orient="vertical" min="0" max="100" value="100">
            </div>
            <button class="mixer-mute-button" data-part="ch">m</button>
          </div>
          <div class="mixer-channel" data-part="oh">
            <div class="mixer-label">oh</div>
            <div class="mixer-slider-container">
              <input type="range" class="mixer-slider" data-part="oh" orient="vertical" min="0" max="100" value="100">
            </div>
            <button class="mixer-mute-button" data-part="oh">m</button>
          </div>
          <div class="mixer-channel" data-part="perc">
            <div class="mixer-label">pc</div>
            <div class="mixer-slider-container">
              <input type="range" class="mixer-slider" data-part="perc" orient="vertical" min="0" max="100" value="100">
            </div>
            <button class="mixer-mute-button" data-part="perc">m</button>
          </div>
        </div>
      </div>

      <div class="email">
        <a href="mailto:contact@crushh.la">contact@crushh.la</a>
      </div>
    </div>
  </div>

  <!-- Tooltip Dialogue -->
  <div class="tooltip-overlay" id="tooltip-overlay"></div>
  <div class="tooltip-dialogue" id="tooltip-dialogue">
    <button class="tooltip-close" id="tooltip-close">×</button>
    <p><strong>How to Use:</strong></p>
    <p><strong>Synth & Controls:</strong> Play piano or use keyboard (desktop) to trigger saw wave synth. Scale selectors choose root note and major/minor. Octave buttons shift pitch. Switch between "bass" and "arp" modes.</p>
    <p class="keyboard-mode-info"><strong>Keyboard Mode (Desktop Only):</strong> A-S-D-F-G-H-J-K (white keys), W-E-T-Y-U (black keys). Z/X shift octave. Visual piano keys light up. Works with recording.</p>
    <p><strong>Bass Mode:</strong> Play notes directly. "rec bass" records 64-step sequence (bars 1-4). 4-count metronome if playing.</p>
    <p><strong>Arp Mode:</strong> Hold key to trigger live arpeggiator. "rec arp" records pattern. Modes: up, down, up+1, down-1, rand, rand+-1. Latch keeps arp playing after release.</p>
    <p><strong>Transport:</strong> "play" restarts from bar 1.1. "stop" halts playback.</p>
    <p><strong>Drums:</strong> 5 sequencers (kick, snare, ch, oh, perc) with 16 steps. Click grid to toggle. 4 sound variants per part. Selectors centered over grids.</p>
    <p><strong>Mixer:</strong> Vertical sliders control volume for each part (bs, arp, ki, sn, ch, oh, pc). "m" buttons below sliders mute individual channels.</p>
    <p><strong>Note:</strong> Keep ringer on for audio. Bass and arp play simultaneously. Have fun!</p>
  </div>

  <script>
    // --- iOS SUPER FIX: PRE-WARM AUDIO CONTEXT WITH A SILENT CLICK ---
    let iosAudioUnlocked = false;
    let audioCtx = null;

    function initAudioCtx() {
      if (!audioCtx) {
        const Ctor = window.AudioContext || window.webkitAudioContext;
        if (!Ctor) {
          audioCtx = null;
          return;
        }
        try {
          audioCtx = new Ctor();
        } catch (e) {
          console.warn("Failed to create AudioContext:", e);
          audioCtx = null;
        }
      }
    }

    function unlockIOSAudio() {
      const Ctor = window.AudioContext || window.webkitAudioContext;
      if (!Ctor) return;
      initAudioCtx();
      if (!audioCtx || iosAudioUnlocked) return;
      iosAudioUnlocked = true;
      try {
        const buffer = audioCtx.createBuffer(1, 1, 44100);
        const source = audioCtx.createBufferSource();
        source.buffer = buffer;
        source.connect(audioCtx.destination);
        source.start(0);
      } catch (e) {
        console.error("iOS unlock error:", e);
      }
    }

    ["touchstart", "touchend", "mousedown"].forEach((evt) => {
      window.addEventListener(
        evt,
        () => {
          initAudioCtx();
          if (!audioCtx) return;
          if (audioCtx.state !== "running") {
            audioCtx.resume().then(unlockIOSAudio).catch(() => {});
          } else {
            unlockIOSAudio();
          }
        },
        { passive: true }
      );
    });

    // Crash + flicker logic for logo
    document.addEventListener("DOMContentLoaded", () => {
      const logo = document.querySelector(".logo");
      const shell = document.querySelector(".logo-shell");
      if (!logo || !shell) return;

      const shouldCrash = sessionStorage.getItem("crushhCrash") === "1";
      let glitchStarted = false;

      function startGlitch() {
        if (glitchStarted) return;
        glitchStarted = true;

        function doGlitch() {
          const intensity = Math.random();
          const maxOffset = 3;
          const maxSkew = 3;

          const dx = (Math.random() - 0.5) * maxOffset * intensity;
          const dy = (Math.random() - 0.5) * maxOffset * intensity;
          const skewX = (Math.random() - 0.5) * maxSkew * intensity;
          const opacity = 0.85 + Math.random() * 0.15;

          logo.style.transition =
            "transform 90ms ease-out, opacity 90ms ease-out, filter 90ms ease-out";
          logo.style.opacity = opacity.toString();
          logo.style.transform = `translate(${dx}px, ${dy}px) skewX(${skewX}deg)`;
          logo.style.filter =
            `contrast(${1.1 + intensity * 0.4}) saturate(${1 + intensity * 0.3})`;

          const resetDelay = 140 + Math.random() * 120;
          setTimeout(() => {
            logo.style.transform = "translate(0, 0) skewX(0deg)";
            logo.style.opacity = "1";
            logo.style.filter = "none";
          }, resetDelay);
        }

        function scheduleGlitch() {
          const delay = 320 + Math.random() * 720;
          setTimeout(() => {
            doGlitch();
            scheduleGlitch();
          }, delay);
        }

        scheduleGlitch();
      }

      if (shouldCrash) {
        sessionStorage.removeItem("crushhCrash");

        shell.style.opacity = "0";
        shell.style.transform = "translateZ(950px) scale(2.9) rotateX(16deg)";
        shell.style.filter = "blur(12px) contrast(1.35)";

        requestAnimationFrame(() => {
          requestAnimationFrame(() => {
            shell.classList.add("crash-in");
          });
        });

        shell.addEventListener(
          "animationend",
          () => {
            shell.classList.remove("crash-in");
            shell.style.opacity = "1";
            shell.style.transform = "translateZ(0)";
            shell.style.filter = "none";
            startGlitch();
          },
          { once: true }
        );
      } else {
        shell.classList.add("normal-in");
        setTimeout(() => {
          startGlitch();
        }, 2600);
      }
    });

    // Synth, drums, transport + sequencer
    document.addEventListener("DOMContentLoaded", () => {
      const hasAudioSupport = !!(window.AudioContext || window.webkitAudioContext);
      if (!hasAudioSupport) {
        console.warn("Web Audio API not supported in this browser. UI will work but audio will be disabled.");
      }

      // --- GLOBAL TRANSPORT ---
      const BPM = 130;
      const BEAT_DUR = 60 / BPM;       // seconds per beat
      const BARS = 4;
      const BEATS_PER_BAR = 4;
      const LOOP_BEATS = BARS * BEATS_PER_BAR; // 16
      const STEPS_PER_BAR = 16;        // 16ths in one bar
      const TOTAL_STEPS = STEPS_PER_BAR * BARS; // 64
      const STEP_DUR = BEAT_DUR / 4;   // 16th note

      // --- MODE & ARP VARIABLES (declared early for use throughout) ---
      let currentMode = "bass";
      let currentArpMode = "up";
      let arpPattern = new Array(TOTAL_STEPS).fill(null);
      let savedArpPattern = null;
      let arpOctaveOffset = 2; // Arp starts at +2 octaves (highest bass octave) and can go up/down from there
      let liveArpInterval = null; // For live arp when holding key
      let liveArpRootNote = null; // Current held note for live arp
      let arpLatch = false; // When true, arp continues playing after key release
      // Removed arpRecordingInterval - arp now records the actual notes played by live arp
      

      let transportStartTime = null;
      let transportRunning = false;
      let stepTimer = null;
      let globalStepCounter = 0;
      let nextStepTime = 0;
      let lastQuarterVisual = null;

      function getAudio() {
        const Ctor = window.AudioContext || window.webkitAudioContext;
        if (!Ctor) return null;
        initAudioCtx();
        if (!audioCtx) return null;
        if (audioCtx.state !== "running") {
          try { audioCtx.resume(); } catch (e) {}
        }
        return audioCtx;
      }

      function getLoopPositionBeats(time) {
        if (transportStartTime === null) return 0;
        const elapsed = Math.max(0, time - transportStartTime);
        const loopDurSec = LOOP_BEATS * BEAT_DUR;
        const beats = elapsed / BEAT_DUR;
        return ((beats % LOOP_BEATS) + LOOP_BEATS) % LOOP_BEATS;
      }

      function timeToGlobalStep(time) {
        if (transportStartTime === null) return 0;
        const elapsed = Math.max(0, time - transportStartTime);
        const stepFloat = elapsed / STEP_DUR;
        return Math.round(stepFloat);
      }

      function startTransport() {
        const ctx = getAudio();
        if (!ctx) return;
        const now = ctx.currentTime;

        // Start immediately with minimal delay for audio scheduling
        transportStartTime = now + 0.05;
        transportRunning = true;

        // Start at step 0, schedule it at transportStartTime
        globalStepCounter = 0;
        nextStepTime = transportStartTime;
        lastQuarterVisual = null;

        if (!stepTimer) {
          stepTimer = setInterval(() => {
            const c = getAudio();
            if (!c || !transportRunning) return;
            const now2 = c.currentTime;
            const lookahead = 0.1;

            while (nextStepTime <= now2 + lookahead) {
              const localStep = globalStepCounter % TOTAL_STEPS;

              // visual 16 quarter notes over 4 bars
              if (stepDots.length) {
                const quarterIndex = Math.floor(localStep / 4); // 0..15
                if (quarterIndex !== lastQuarterVisual) {
                  stepDots.forEach((dot, idx) => {
                    dot.classList.toggle("active", idx === quarterIndex);
                  });
                  lastQuarterVisual = quarterIndex;
                }
              }

              // schedule drums & synth notes for this step
              scheduleDrumsForStep(localStep, nextStepTime);
              scheduleSynthForStep(localStep, nextStepTime);
              scheduleArpForStep(localStep, nextStepTime);

              // Increment AFTER scheduling so step 0 plays at transportStartTime
              globalStepCounter++;
              nextStepTime += STEP_DUR;
            }
          }, 25);
        }
      }

      function stopTransport() {
        transportRunning = false;
        if (stepTimer) {
          clearInterval(stepTimer);
          stepTimer = null;
        }
        lastQuarterVisual = null;
        globalStepCounter = 0;
        if (stepDots.length) {
          stepDots.forEach(dot => dot.classList.remove("active"));
        }
        // Clear sequencer voice when transport stops
        sequencerVoice = null;
        lastSequencerFreq = null;
      }

      // --- SCALE: Dynamic scale system ---
      const noteFreq = {
        C1: 32.70,
        "C#1": 34.65,
        D1: 36.71,
        "D#1": 38.89,
        E1: 41.20,
        F1: 43.65,
        "F#1": 46.25,
        G1: 49.00,
        "G#1": 51.91,
        A1: 55.00,
        "A#1": 58.27,
        B1: 61.74,
        C2: 65.41
      };

      const keyboardOrder = [
        "C1","C#1","D1","D#1","E1","F1","F#1","G1","G#1","A1","A#1","B1","C2"
      ];

      // Scale intervals: major and minor
      const scaleIntervals = {
        major: [0, 2, 4, 5, 7, 9, 11], // W-W-H-W-W-W-H (whole, whole, half, whole, whole, whole, half)
        minor: [0, 2, 3, 5, 7, 8, 10]  // W-H-W-W-H-W-W (natural minor)
      };

      // Map root names to semitone offsets from C
      const rootOffsets = {
        "C": 0, "C#": 1, "D": 2, "D#": 3, "E": 4, "F": 5,
        "F#": 6, "G": 7, "G#": 8, "A": 9, "A#": 10, "B": 11
      };

      // Current scale settings (default: A Major)
      let currentScaleRoot = "A";
      let currentScaleMode = "major";
      let scaleMap = {};

      // Function to generate scale notes based on root and mode
      function generateScaleNotes(root, mode) {
        const rootOffset = rootOffsets[root];
        const intervals = scaleIntervals[mode];
        const scaleNotes = [];
        const noteNames = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"];
        
        // Generate scale degrees (semitone values relative to root, modulo 12)
        const scaleSemitones = intervals.map(interval => (rootOffset + interval) % 12);
        
        // Find all notes in keyboardOrder that match any scale degree
        keyboardOrder.forEach(note => {
          // Extract note name and octave
          const noteMatch = note.match(/^([A-G]#?)(\d)$/);
          if (!noteMatch) return;
          
          const noteName = noteMatch[1];
          const semitone = rootOffsets[noteName];
          
          // Check if this note's semitone value matches any scale degree
          if (scaleSemitones.includes(semitone)) {
            scaleNotes.push(note);
          }
        });
        
        return scaleNotes;
      }

      // Function to update scaleMap based on current root and mode
      function updateScaleMap() {
        const scaleNotes = generateScaleNotes(currentScaleRoot, currentScaleMode);
        const scaleSet = new Set(scaleNotes);
        scaleMap = {};
        
        keyboardOrder.forEach((note, idx) => {
          if (scaleSet.has(note)) {
            scaleMap[note] = note;
          } else {
            // Find nearest scale note
            let best = null;
            let bestDist = Infinity;
            scaleNotes.forEach((n) => {
              const j = keyboardOrder.indexOf(n);
              if (j === -1) return;
              const d = Math.abs(j - idx);
              if (d < bestDist) {
                bestDist = d;
                best = n;
              }
            });
            scaleMap[note] = best || note;
          }
        });
      }

      // Initialize with A Major (current default)
      updateScaleMap();

      // Add event listeners for scale selectors
      const scaleRootSelect = document.getElementById("scale-root");
      const scaleModeSelect = document.getElementById("scale-mode");
      
      if (scaleRootSelect) {
        scaleRootSelect.addEventListener("change", (e) => {
          currentScaleRoot = e.target.value;
          updateScaleMap();
        });
      }
      
      if (scaleModeSelect) {
        scaleModeSelect.addEventListener("change", (e) => {
          currentScaleMode = e.target.value;
          updateScaleMap();
        });
      }

      // Octave control buttons
      const octaveUpBtn = document.getElementById("octave-up");
      const octaveDownBtn = document.getElementById("octave-down");
      
      if (octaveUpBtn) {
        octaveUpBtn.addEventListener("click", () => {
          if (currentMode === "arp") {
            arpOctaveOffset = Math.min(arpOctaveOffset + 1, 5); // Arp can go higher
          } else {
            octaveOffset = Math.min(octaveOffset + 1, 2); // Limit to +2 octaves for bass
          }
        });
      }
      
      if (octaveDownBtn) {
        octaveDownBtn.addEventListener("click", () => {
          if (currentMode === "arp") {
            arpOctaveOffset = Math.max(arpOctaveOffset - 1, 0); // Arp can't go below base
          } else {
            octaveOffset = Math.max(octaveOffset - 1, -2); // Limit to -2 octaves for bass
          }
        });
      }

      const synthModeSelect = document.getElementById("synth-mode");
      const arpModeSelect = document.getElementById("arp-mode");
      const arpLatchBtn = document.getElementById("arp-latch");
      const modeSelectors = document.getElementById("mode-selectors");

      function updateModeUI() {
        const recBtn = document.getElementById("seq-record");
        if (currentMode === "arp") {
          if (modeSelectors) modeSelectors.classList.add("show-arp");
          // Always update button text when switching modes, even if looping
          // This allows recording arp over bass and vice versa
          if (recBtn) {
            if (recBtn.classList.contains("looping")) {
              // Reset looping state when switching modes so you can record over the other pattern
              recBtn.classList.remove("looping");
              recBtn.textContent = "rec arp";
            } else if (!recBtn.classList.contains("recording")) {
              recBtn.textContent = "rec arp";
            }
          }
        } else {
          if (modeSelectors) modeSelectors.classList.remove("show-arp");
          // Always update button text when switching modes, even if looping
          if (recBtn) {
            if (recBtn.classList.contains("looping")) {
              // Reset looping state when switching modes so you can record over the other pattern
              recBtn.classList.remove("looping");
              recBtn.textContent = "rec bass";
            } else if (!recBtn.classList.contains("recording")) {
              recBtn.textContent = "rec bass";
            }
          }
        }
        
        // Update latch button state
        if (arpLatchBtn) {
          arpLatchBtn.classList.toggle("active", arpLatch);
        }
      }

      if (synthModeSelect) {
        synthModeSelect.addEventListener("change", (e) => {
          currentMode = e.target.value;
          updateModeUI();
        });
      }

      if (arpModeSelect) {
        arpModeSelect.addEventListener("change", (e) => {
          currentArpMode = e.target.value;
          // Restart live arp if currently playing with new mode
          if (liveArpRootNote) {
            startLiveArp(liveArpRootNote);
          }
        });
      }

      // Latch button for arp
      if (arpLatchBtn) {
        arpLatchBtn.addEventListener("click", () => {
          arpLatch = !arpLatch;
          // If turning latch off and arp is playing, stop it
          if (!arpLatch && liveArpRootNote) {
            stopLiveArp();
          }
          updateModeUI();
        });
      }


      updateModeUI();

      function createDistortionCurve(amount) {
        const k = typeof amount === "number" ? amount : 1;
        const n = 44100;
        const curve = new Float32Array(n);
        let x;
        const norm = Math.tanh(k);
        for (let i = 0; i < n; ++i) {
          x = (i * 2) / n - 1;
          curve[i] = Math.tanh(k * x) / norm;
        }
        return curve;
      }

      // Metronome for recording - plays during entire 4-bar recording
      let metronomeMasterGain = null; // Master gain node to control all metronome clicks
      
      function playMetronomeClick(when, volume = 0.35) {
        const ctx = getAudio();
        if (!ctx) return;
        
        // Create a short click sound using a brief sine wave burst
        const osc = ctx.createOscillator();
        const gain = ctx.createGain();
        
        osc.type = "sine";
        osc.frequency.setValueAtTime(1000, when); // 1kHz click
        
        gain.gain.setValueAtTime(0, when);
        gain.gain.linearRampToValueAtTime(volume, when + 0.001);
        gain.gain.exponentialRampToValueAtTime(0.001, when + 0.01);
        gain.gain.setValueAtTime(0, when + 0.02);
        
        osc.connect(gain);
        // Connect through master gain node if it exists, otherwise direct to destination
        if (metronomeMasterGain) {
          gain.connect(metronomeMasterGain);
        } else {
          gain.connect(ctx.destination);
        }
        
        osc.start(when);
        osc.stop(when + 0.02);
      }
      
      function startRecordingMetronome(startTime, endTime) {
        const ctx = getAudio();
        if (!ctx) return;
        
        // Stop any existing metronome
        stopRecordingMetronome();
        
        // Create master gain node for metronome (allows muting when stopped)
        metronomeMasterGain = ctx.createGain();
        metronomeMasterGain.gain.setValueAtTime(1, ctx.currentTime);
        metronomeMasterGain.connect(ctx.destination);
        
        // Calculate all beat times during recording (16 beats = 4 bars)
        const beatTimes = [];
        for (let i = 0; i < LOOP_BEATS; i++) {
          beatTimes.push(startTime + i * BEAT_DUR);
        }
        
        // Schedule all metronome clicks
        const now = ctx.currentTime;
        beatTimes.forEach(beatTime => {
          if (beatTime >= now && beatTime <= endTime) {
            playMetronomeClick(beatTime, 0.35);
          }
        });
      }
      
      function stopRecordingMetronome() {
        // Mute the master gain node to stop all metronome clicks
        if (metronomeMasterGain) {
          const ctx = getAudio();
          if (ctx) {
            const now = ctx.currentTime;
            metronomeMasterGain.gain.setValueAtTime(0, now);
            // Disconnect and clear after a short delay
            setTimeout(() => {
              if (metronomeMasterGain) {
                try {
                  metronomeMasterGain.disconnect();
                } catch (e) {}
                metronomeMasterGain = null;
              }
            }, 100);
          }
        }
      }

      // --- LIVE SYNTH VOICE (monophonic) ---
      let currentVoice = null;
      const glideTime = 0.16; // Portamento time (160ms to match Serum 2)
      let octaveOffset = 0; // Octave offset: 0 = normal, 1 = +1 octave, -1 = -1 octave

      function startLiveArp(rootNote) {
        // Only restart if the root note has actually changed
        if (liveArpRootNote === rootNote && liveArpInterval) {
          return; // Same note, keep playing
        }
        
        // Root note changed or starting fresh - restart arp
        if (liveArpInterval) {
          clearInterval(liveArpInterval);
          liveArpInterval = null;
        }
        
        liveArpRootNote = rootNote;
        const ctx = getAudio();
        if (!ctx) return;
        
        // Start arp immediately
        const arpNotes = generateArpNotes(rootNote, currentArpMode || "up");
        if (arpNotes.length === 0) return;
        
        let arpIndex = 0;
        const noteDuration = STEP_DUR; // 16th note timing
        
        const playNextNote = () => {
          // Only play if we're still on the same root note
          if (!liveArpRootNote || liveArpRootNote !== rootNote) {
            if (liveArpInterval) {
              clearInterval(liveArpInterval);
              liveArpInterval = null;
            }
            return;
          }
          
          const note = arpNotes[arpIndex % arpNotes.length];
          const freq = getNoteFrequency(note);
          if (freq) {
            // Apply arp octave offset (separate from bass)
            // This shifts the whole recording up/down when octave buttons are pressed
            const adjustedFreq = freq * Math.pow(2, arpOctaveOffset);
            const now = ctx.currentTime;
            createArpVoice(adjustedFreq, now);
            
            // Record the actual arp note being played if we're recording
            if (arpRecState === "recording" && recStartTime !== null && recEndTime !== null) {
              const elapsedFromRecStart = Math.max(0, now - recStartTime);
              const stepFloat = elapsedFromRecStart / STEP_DUR;
              let localStart = Math.round(stepFloat);
              const step0Threshold = STEP_DUR * 0.75;
              if (elapsedFromRecStart <= step0Threshold) {
                localStart = 0;
              }
              localStart = Math.max(0, Math.min(localStart, TOTAL_STEPS - 1));
              
              // Only record if we haven't exceeded the recording end time
              if (now < recEndTime && localStart < TOTAL_STEPS) {
                // Record the actual note being played, not the root
                arpPattern[localStart] = { rootNote: note, arpMode: currentArpMode };
              }
            }
          }
          arpIndex++;
        };
        
        // Play first note immediately
        playNextNote();
        
        // Then continue at 16th note intervals
        const intervalMs = STEP_DUR * 1000;
        liveArpInterval = setInterval(playNextNote, intervalMs);
      }
      
      function stopLiveArp() {
        if (liveArpInterval) {
          clearInterval(liveArpInterval);
          liveArpInterval = null;
        }
        liveArpRootNote = null;
      }

      function startOrGlideToNote(rawNote) {
        const mapped = scaleMap[rawNote] || rawNote;
        
        if (currentMode === "arp") {
          // Start live arp when key is held
          startLiveArp(mapped);
          return;
        }
        
        let freq = noteFreq[mapped];
        if (!freq) return;
        
        // Apply octave offset (multiply by 2 for each octave up, divide for each octave down)
        if (octaveOffset !== 0) {
          freq = freq * Math.pow(2, octaveOffset);
        }

        const ctx = getAudio();
        if (!ctx) return;
        const now = ctx.currentTime;

        if (!currentVoice) {
          const osc = ctx.createOscillator();
          const gain = ctx.createGain();
          const distortion = ctx.createWaveShaper();

          osc.type = "sawtooth";
          osc.frequency.setValueAtTime(freq, now);

          distortion.curve = createDistortionCurve(4);
          distortion.oversample = "2x";

          // Apply mixer gain for bass
          const bassMixerGain = mixerMuted.bass ? 0 : partGain.bass;
          gain.gain.setValueAtTime(0, now);
          gain.gain.linearRampToValueAtTime(0.23 * bassMixerGain, now + 0.02);

          osc.connect(distortion);
          distortion.connect(gain);
          gain.connect(ctx.destination);

          osc.start(now);

          currentVoice = { osc, gain };
        } else {
          const { osc } = currentVoice;
          osc.frequency.cancelScheduledValues(now);
          const currentFreq = osc.frequency.value;
          osc.frequency.setValueAtTime(currentFreq, now);
          osc.frequency.linearRampToValueAtTime(freq, now + glideTime);
        }
      }

      function stopCurrentVoice() {
        // Stop live arp if in arp mode (unless latch is enabled)
        if (currentMode === "arp") {
          // Only stop arp if latch is off
          if (!arpLatch) {
            stopLiveArp();
          }
          return;
        }
        
        if (!currentVoice) return;
        const ctx = getAudio();
        if (!ctx) return;
        const now = ctx.currentTime;
        const { osc, gain } = currentVoice;

        gain.gain.cancelScheduledValues(now);
        gain.gain.setValueAtTime(gain.gain.value, now);
        gain.gain.linearRampToValueAtTime(0, now + 0.06);

        osc.stop(now + 0.07);
        currentVoice = null;
      }

      // --- DRUMS: one-shots, 1-bar patterns ---
      const drumParts = ["kick","snare","ch","oh","perc"];
      const drumFiles = {
        kick: ["sounds2/Kick1.wav","sounds2/Kick2.wav","sounds2/Kick3.wav","sounds2/Kick4.wav"],
        snare:["sounds2/Snare1.wav","sounds2/Snare2.wav","sounds2/Snare3.wav","sounds2/Snare4.wav"],
        ch:   ["sounds2/CH1.wav","sounds2/CH2.wav","sounds2/CH3.wav","sounds2/CH4.wav"],
        oh:   ["sounds2/OH1.wav","sounds2/OH2.wav","sounds2/OH3.wav","sounds2/OH4.wav"],
        perc: ["sounds2/Perc1.wav","sounds2/Perc2.wav","sounds2/Perc3.wav","sounds2/Perc4.wav"]
      };

      let drumBuffers = {
        kick: [null,null,null,null],
        snare:[null,null,null,null],
        ch:   [null,null,null,null],
        oh:   [null,null,null,null],
        perc: [null,null,null,null]
      };

      let drumLoaded = false;
      let drumLoading = false;

      const drumPatterns = {
        kick: new Array(16).fill(false),
        snare:new Array(16).fill(false),
        ch:   new Array(16).fill(false),
        oh:   new Array(16).fill(false),
        perc: new Array(16).fill(false)
      };


      // Part mixer gain levels (0-1, where 1 = 100%)
      const partGain = {
        kick: 1.0,
        snare: 1.0,
        ch: 1.0,
        oh: 1.0,
        perc: 1.0,
        bass: 1.0,
        arp: 1.0
      };

      // Mixer mute states (separate from existing mutes)
      const mixerMuted = {
        kick: false,
        snare: false,
        ch: false,
        oh: false,
        perc: false,
        bass: false,
        arp: false
      };


      const drumVariantIndex = {
        kick: 0,
        snare:0,
        ch:   0,
        oh:   0,
        perc: 0
      };

      async function loadDrumBuffers(ctx) {
        if (!ctx || drumLoaded || drumLoading) return;
        drumLoading = true;
        try {
          for (const part of drumParts) {
            const urls = drumFiles[part];
            for (let i = 0; i < urls.length; i++) {
              const res = await fetch(urls[i]);
              const arr = await res.arrayBuffer();
              drumBuffers[part][i] = await ctx.decodeAudioData(arr);
            }
          }
          drumLoaded = true;
        } catch (e) {
          console.warn("Error loading drum one-shots:", e);
        } finally {
          drumLoading = false;
        }
      }

      function scheduleDrumsForStep(globalStep, when) {
        if (!drumLoaded) return;
        const ctx = getAudio();
        if (!ctx) return;

        // drums: 1-bar 16-step pattern, repeating across 4 bars
        const localStep = globalStep % 16;

        for (const part of drumParts) {
          if (!drumPatterns[part][localStep]) continue;

          const variant = drumVariantIndex[part] || 0;
          const buffer = drumBuffers[part][variant];
          if (!buffer) continue;

          const src = ctx.createBufferSource();
          const gain = ctx.createGain();

          src.buffer = buffer;
          // Apply mixer gain (0.4 base * mixer gain)
          const mixerGain = mixerMuted[part] ? 0 : partGain[part];
          gain.gain.setValueAtTime(0.4 * mixerGain, when);

          src.connect(gain);
          gain.connect(ctx.destination);
          src.start(when);
        }
      }

      // --- SYNTH SEQUENCER (64-step mono pattern) ---
      let synthPattern = new Array(TOTAL_STEPS).fill(null); // each step: {note, lengthSeconds} - start quantized to 16ths, duration preserved
      let savedSynthPattern = null; // Saved pattern that persists after stop until new recording
      // Separate recording states for bass and arp to make them fully independent
      let bassRecState = "idle"; // "idle" | "count-in" | "recording" | "playing"
      let arpRecState = "idle"; // "idle" | "count-in" | "recording" | "playing"
      let recState = "idle"; // Legacy: tracks if ANY mode is recording/playing (for backward compatibility)
      let recStartTime = null;
      let recEndTime = null;
      let recStartGlobalStep = 0;
      let pendingNotes = {}; // mappedNote -> { startGlobalStep, localStart, actualStartTime }
      let currentRecordedNote = null;
      let preRecordingNotes = {}; // Notes held before recording starts: mappedNote -> { pressTime }
      
      // Sequencer voice for portamento (separate from live voice)
      let sequencerVoice = null;
      let lastSequencerFreq = null; // Track last frequency for always-on portamento

      // ARP FUNCTIONS
      // FALLBACK VERSION: Crystal Castles / deadmau5 style pluck with simple delay
      // Delay: 16th note, 25% mix, no feedback
      function createArpVoice(freq, startTime) {
        const ctx = getAudio();
        if (!ctx || !freq) return null;
        const now = ctx.currentTime;
        const t0 = Math.max(startTime, now);
        
        // Crystal Castles / deadmau5 style pluck - bright, crisp, monophonic
        const osc = ctx.createOscillator();
        osc.type = "sawtooth"; // Bright sawtooth for that classic pluck character
        
        // Filter with envelope for that pluck character
        const filter = ctx.createBiquadFilter();
        filter.type = "lowpass";
        filter.Q.setValueAtTime(2, t0); // Some resonance for brightness
        
        // Filter envelope: opens quickly then closes for pluck
        const filterAttack = 0.001;
        const filterDecay = 0.08;
        const filterSustainFreq = 800; // Lower sustain frequency
        const filterPeakFreq = 8000; // Bright peak
        
        filter.frequency.setValueAtTime(filterSustainFreq, t0);
        filter.frequency.linearRampToValueAtTime(filterPeakFreq, t0 + filterAttack);
        filter.frequency.exponentialRampToValueAtTime(filterSustainFreq, t0 + filterAttack + filterDecay);
        
        osc.frequency.setValueAtTime(freq, t0);
        
        const gain = ctx.createGain();
        // Short, snappy ADSR for pluck
        const attack = 0.002; // Very quick attack
        const decay = 0.12; // Quick decay
        const sustain = 0.1; // Low sustain
        const release = 0.03; // Short release
        const totalDuration = attack + decay + release;
        
        // Apply mixer gain for arp
        const arpMixerGain = mixerMuted.arp ? 0 : partGain.arp;
        gain.gain.setValueAtTime(0, t0);
        gain.gain.linearRampToValueAtTime(0.35 * arpMixerGain, t0 + attack);
        gain.gain.exponentialRampToValueAtTime(sustain * arpMixerGain, t0 + attack + decay);
        gain.gain.setValueAtTime(sustain * arpMixerGain, t0 + attack + decay);
        gain.gain.exponentialRampToValueAtTime(0.001, t0 + totalDuration);
        
        // Light delay for depth (Crystal Castles style)
        const delay = ctx.createDelay(1.0);
        const delayGain = ctx.createGain();
        delay.delayTime.setValueAtTime(BEAT_DUR / 4, t0); // 16th note delay
        delayGain.gain.setValueAtTime(0.25, t0);
        
        osc.connect(filter);
        filter.connect(gain);
        gain.connect(ctx.destination);
        gain.connect(delayGain);
        delayGain.connect(delay);
        delay.connect(ctx.destination);
        
        osc.start(t0);
        osc.stop(t0 + totalDuration + 0.1);
        
        return { osc, gain, filter, stopTime: t0 + totalDuration };
      }

      // Helper function to get frequency for any note, even if not in noteFreq
      // Calculates frequency based on octave: freq = baseFreq * 2^(octaveDifference)
      function getNoteFrequency(note) {
        // If note exists in noteFreq, return it
        if (noteFreq[note]) return noteFreq[note];
        
        // Extract note name and octave
        const noteMatch = note.match(/^([A-G]#?)(\d)$/);
        if (!noteMatch) return null;
        
        const noteName = noteMatch[1];
        const octave = parseInt(noteMatch[2], 10);
        
        // Find the base frequency for this note in octave 1
        const baseNote = noteName + "1";
        const baseFreq = noteFreq[baseNote];
        if (!baseFreq) return null;
        
        // Calculate frequency for the target octave: freq = baseFreq * 2^(octave - 1)
        const octaveDifference = octave - 1;
        return baseFreq * Math.pow(2, octaveDifference);
      }

      // Helper function to shift a note by an octave
      function shiftNoteOctave(note, octaveShift) {
        const noteMatch = note.match(/^([A-G]#?)(\d)$/);
        if (!noteMatch) return note;
        const noteName = noteMatch[1];
        const octave = parseInt(noteMatch[2], 10);
        return noteName + (octave + octaveShift);
      }

      // Helper function to get scale notes in a specific octave
      function getScaleNotesInOctave(octave) {
        const rootOffset = rootOffsets[currentScaleRoot];
        const intervals = scaleIntervals[currentScaleMode];
        const noteNames = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"];
        const notesInOctave = [];
        
        // Generate scale degrees (semitone values relative to root, modulo 12)
        const scaleSemitones = intervals.map(interval => (rootOffset + interval) % 12);
        
        // For each scale degree, create a note in the specified octave
        scaleSemitones.forEach(semitone => {
          const noteName = noteNames[semitone];
          const note = noteName + octave;
          notesInOctave.push(note);
        });
        
        return notesInOctave;
      }

      function generateArpNotes(rootNote, mode) {
        if (!rootNote) return [];
        const scaleNotes = generateScaleNotes(currentScaleRoot, currentScaleMode);
        if (scaleNotes.length === 0) return [];
        
        // Sort scaleNotes by pitch (frequency) to ensure we always go up
        const sortedScaleNotes = [...scaleNotes].sort((a, b) => {
          const freqA = getNoteFrequency(a) || 0;
          const freqB = getNoteFrequency(b) || 0;
          return freqA - freqB;
        });
        
        const rootIndex = sortedScaleNotes.findIndex(note => note === rootNote);
        if (rootIndex === -1) return [];
        const notes = [];
        
        if (mode === "up") {
          // For "up" pattern, always go up in pitch
          // If we run out of notes, continue to next octave
          for (let i = 0; i < 4; i++) {
            let scaleIndex = rootIndex + i;
            
            // If we've gone past the end of sortedScaleNotes, continue to next octave
            if (scaleIndex >= sortedScaleNotes.length) {
              // Calculate how many scale steps we need from root
              const scaleStepsFromRoot = i;
              // Find which scale degree this corresponds to (wrapping around)
              const scaleDegreeIndex = scaleStepsFromRoot % sortedScaleNotes.length;
              const baseNote = sortedScaleNotes[scaleDegreeIndex];
              
              // Extract note name and octave
              const noteMatch = baseNote.match(/^([A-G]#?)(\d)$/);
              if (noteMatch) {
                const noteName = noteMatch[1];
                const octave = parseInt(noteMatch[2], 10);
                const nextOctaveNote = noteName + (octave + 1);
                
                // Always use the next octave note, even if it doesn't exist in noteFreq
                // The frequency will be calculated as baseFreq * 2 (one octave up)
                notes.push(nextOctaveNote);
              } else {
                notes.push(baseNote);
              }
            } else {
              notes.push(sortedScaleNotes[scaleIndex]);
            }
          }
        } else if (mode === "down") {
          // For "down" pattern, always go down in pitch
          // If we run out of notes, continue to previous octave
          for (let i = 0; i < 4; i++) {
            let scaleIndex = rootIndex - i;
            
            // If we've gone below 0, continue to previous octave
            if (scaleIndex < 0) {
              // Calculate how many scale steps we need from root (going down)
              const scaleStepsFromRoot = i;
              // Find which scale degree this corresponds to (wrapping around backwards)
              // When going down from rootIndex by i steps and wrapping: (rootIndex - i) mod length
              // Since scaleIndex is negative, we add length to get positive equivalent
              const scaleDegreeIndex = ((rootIndex - scaleStepsFromRoot) % sortedScaleNotes.length + sortedScaleNotes.length) % sortedScaleNotes.length;
              const baseNote = sortedScaleNotes[scaleDegreeIndex];
              
              // Extract note name and octave
              const noteMatch = baseNote.match(/^([A-G]#?)(\d)$/);
              if (noteMatch) {
                const noteName = noteMatch[1];
                const octave = parseInt(noteMatch[2], 10);
                const prevOctaveNote = noteName + (octave - 1);
                
                // Always use the previous octave note, even if it doesn't exist in noteFreq
                // The frequency will be calculated as baseFreq / 2 (one octave down)
                notes.push(prevOctaveNote);
              } else {
                notes.push(baseNote);
              }
            } else {
              notes.push(sortedScaleNotes[scaleIndex]);
            }
          }
        } else if (mode === "up+1") {
          // Play 4 notes going up, then the same 4 notes one octave up
          const firstFourNotes = [];
          for (let i = 0; i < 4; i++) {
            let scaleIndex = rootIndex + i;
            
            if (scaleIndex >= sortedScaleNotes.length) {
              // Wrap around to next octave
              const scaleStepsFromRoot = i;
              const scaleDegreeIndex = scaleStepsFromRoot % sortedScaleNotes.length;
              const baseNote = sortedScaleNotes[scaleDegreeIndex];
              
              // Extract note name and octave, then add one octave
              const noteMatch = baseNote.match(/^([A-G]#?)(\d)$/);
              if (noteMatch) {
                const noteName = noteMatch[1];
                const octave = parseInt(noteMatch[2], 10);
                firstFourNotes.push(noteName + (octave + 1));
              } else {
                firstFourNotes.push(baseNote);
              }
            } else {
              firstFourNotes.push(sortedScaleNotes[scaleIndex]);
            }
          }
          
          // Add the first 4 notes
          notes.push(...firstFourNotes);
          
          // Add the same 4 notes shifted up one octave
          firstFourNotes.forEach(note => {
            notes.push(shiftNoteOctave(note, 1));
          });
        } else if (mode === "down-1") {
          // Play 4 notes going down, then the same 4 notes one octave down
          const firstFourNotes = [];
          for (let i = 0; i < 4; i++) {
            let scaleIndex = rootIndex - i;
            
            if (scaleIndex < 0) {
              // Wrap around to previous octave
              const scaleStepsFromRoot = i;
              const scaleDegreeIndex = ((rootIndex - scaleStepsFromRoot) % sortedScaleNotes.length + sortedScaleNotes.length) % sortedScaleNotes.length;
              const baseNote = sortedScaleNotes[scaleDegreeIndex];
              
              // Extract note name and octave, then subtract one octave
              const noteMatch = baseNote.match(/^([A-G]#?)(\d)$/);
              if (noteMatch) {
                const noteName = noteMatch[1];
                const octave = parseInt(noteMatch[2], 10);
                firstFourNotes.push(noteName + (octave - 1));
              } else {
                firstFourNotes.push(baseNote);
              }
            } else {
              firstFourNotes.push(sortedScaleNotes[scaleIndex]);
            }
          }
          
          // Add the first 4 notes
          notes.push(...firstFourNotes);
          
          // Add the same 4 notes shifted down one octave
          firstFourNotes.forEach(note => {
            notes.push(shiftNoteOctave(note, -1));
          });
        } else if (mode === "rand") {
          // Randomly select notes from the active octave (root note's octave)
          const rootMatch = rootNote.match(/^([A-G]#?)(\d)$/);
          if (rootMatch) {
            const rootOctave = parseInt(rootMatch[2], 10);
            const notesInOctave = getScaleNotesInOctave(rootOctave);
            
            if (notesInOctave.length > 0) {
              // Randomly select 4 notes from the active octave
              for (let i = 0; i < 4; i++) {
                const randomIndex = Math.floor(Math.random() * notesInOctave.length);
                notes.push(notesInOctave[randomIndex]);
              }
            }
          }
        } else if (mode === "rand+-1") {
          // Randomly select notes from active octave, one octave up, and one octave down
          const rootMatch = rootNote.match(/^([A-G]#?)(\d)$/);
          if (rootMatch) {
            const rootOctave = parseInt(rootMatch[2], 10);
            const allCandidateNotes = [];
            
            // Get notes from root octave, one octave up, and one octave down
            [-1, 0, 1].forEach(octaveShift => {
              const notesInOctave = getScaleNotesInOctave(rootOctave + octaveShift);
              allCandidateNotes.push(...notesInOctave);
            });
            
            if (allCandidateNotes.length > 0) {
              // Randomly select 4 notes from all candidate notes
              for (let i = 0; i < 4; i++) {
                const randomIndex = Math.floor(Math.random() * allCandidateNotes.length);
                notes.push(allCandidateNotes[randomIndex]);
              }
            }
          }
        }
        
        return notes;
      }

      function scheduleArpForStep(globalStep, when) {
        // Play arp if pattern exists, independent of recording state
        // This allows arp to play while bass is being recorded and vice versa
        
        const localStep = globalStep % TOTAL_STEPS;
        
        // Check if there's a recorded note at this step
        // The live arp records the actual arp notes being played, not root notes
        const evt = arpPattern[localStep];
        if (!evt || !evt.rootNote) return;
        
        // Play the recorded note directly (rootNote field stores the actual note played by live arp)
        const note = evt.rootNote;
        const freq = getNoteFrequency(note);
        if (freq) {
          // Apply arp octave offset (separate from bass)
          // This shifts the whole recording up/down when octave buttons are pressed
          const adjustedFreq = freq * Math.pow(2, arpOctaveOffset);
          createArpVoice(adjustedFreq, when);
        }
      }

      function scheduleSynthForStep(globalStep, when) {
        // Play bass if pattern exists, independent of recording state
        // This allows bass to play while arp is being recorded and vice versa
        
        const localStep = globalStep % TOTAL_STEPS;
        const evt = synthPattern[localStep];
        if (!evt) return;

        // Use precise duration if available, otherwise fall back to step-based (for backwards compatibility)
        const duration = evt.lengthSeconds !== undefined 
          ? evt.lengthSeconds 
          : (evt.lengthSteps * STEP_DUR);
        
        // Check for next note to determine if we should extend this note (Serum 2 mono portamento style)
        // In mono portamento mode, we want continuous sound with no gaps
        // IMPORTANT: Handle loop boundary correctly - step 63 -> step 0
        const nextStep = (localStep + 1) % TOTAL_STEPS;
        const nextEvt = synthPattern[nextStep];
        const hasNextNote = nextEvt !== null;
        
        // Calculate timing
        const noteEndTime = when + duration;
        const nextNoteStartTime = when + STEP_DUR;
        const gap = nextNoteStartTime - noteEndTime;
        
        // If there's a next note and a gap, we need to extend this note to eliminate the gap
        // This creates the continuous, tied-together sound of Serum 2 mono portamento
        let adjustedDuration = duration;
        if (hasNextNote && gap > 0) {
          // Extend this note to connect seamlessly to the next note
          // This ensures no gaps in the continuous voice, including loop boundary
          adjustedDuration = duration + gap;
        }
        
        // Always pass as legato if there's a next note (for continuous voice)
        // This ensures seamless transitions including loop boundary (step 63 -> step 0)
        const isLegato = hasNextNote;
        
        // Pass to triggerSeqNote - use adjusted duration to eliminate gaps
        triggerSeqNote(evt.note, adjustedDuration, when, isLegato);
      }

      function triggerSeqNote(noteName, durationSeconds, startTime, isLegato = false) {
        const mapped = scaleMap[noteName] || noteName;
        let freq = noteFreq[mapped];
        if (!freq) return;
        
        // Apply octave offset (multiply by 2 for each octave up, divide for each octave down)
        if (octaveOffset !== 0) {
          freq = freq * Math.pow(2, octaveOffset);
        }
        const ctx = getAudio();
        if (!ctx) return;

        const t0 = Math.max(startTime, ctx.currentTime);
        const now = ctx.currentTime;

        // Use exact duration - no quantization or rounding
        const total = Math.max(0.01, durationSeconds);

        // Serum 2 style monophonic portamento:
        // - Always maintain one continuous voice (never silence)
        // - If there's any active voice or recently ended voice, reuse it
        // - Only change frequency, don't retrigger envelope for legato notes
        // - Always glide from current/last frequency
        
        let startFreq = freq;
        let voiceIsActive = false;
        const legatoWindow = 0.15; // 150ms window for legato (generous for continuous voice and loop boundary)
        
        // Check if we have an active voice or a recently ended voice
        // In mono portamento mode, we want to maintain continuous sound
        // IMPORTANT: Check if voice will be active at scheduled start time (t0), not current time (now)
        // This is crucial for loop boundary where we're scheduling ahead
        if (sequencerVoice && sequencerVoice.osc) {
          try {
            // Check if voice will still be playing when this note starts
            // Use t0 (scheduled start time) instead of now for accurate detection
            // Add small buffer to account for timing variations
            const voiceEndBuffer = 0.01; // 10ms buffer for timing safety
            if (sequencerVoice.noteEndTime > (t0 - voiceEndBuffer)) {
              // Voice will still be playing when this note starts - definitely legato
              voiceIsActive = true;
              startFreq = sequencerVoice.osc.frequency.value;
              isLegato = true;
            } else {
              // Voice ended before this note starts - check if within legato window
              const timeSinceEnd = t0 - sequencerVoice.noteEndTime;
              if (timeSinceEnd <= legatoWindow && timeSinceEnd >= -voiceEndBuffer && lastSequencerFreq !== null) {
                // Within legato window - reactivate voice for seamless connection
                // This handles loop boundary where note at 4.1 needs to tie into 1.1
                voiceIsActive = true;
                startFreq = lastSequencerFreq;
                isLegato = true;
              } else if (lastSequencerFreq !== null) {
                // Outside legato window but still glide from last frequency (portamento always on)
                startFreq = lastSequencerFreq;
              }
            }
          } catch (e) {
            // If osc is invalid, fall back to last frequency
            if (lastSequencerFreq !== null) {
              startFreq = lastSequencerFreq;
            }
          }
        } else if (lastSequencerFreq !== null) {
          // No active voice, but we have last frequency - always glide from it (portamento always on)
          startFreq = lastSequencerFreq;
        }

        // Serum 2 style: If voice is active (legato), reuse it - only change frequency, maintain envelope
        // This creates the continuous, tied-together sound with no gaps
        if (voiceIsActive && sequencerVoice && sequencerVoice.osc && sequencerVoice.gain) {
          const { osc, gain } = sequencerVoice;
          
          // Get current frequency and gain values
          const currentFreq = osc.frequency.value;
          const currentGain = gain.gain.value;
          
          // Cancel any scheduled frequency changes from now onwards
          osc.frequency.cancelScheduledValues(now);
          
          // Set current frequency at now to maintain it until note starts
          // This prevents any unwanted frequency changes between now and t0
          osc.frequency.setValueAtTime(currentFreq, now);
          
          // Smooth glide to new frequency (Serum 2 portamento - 160ms)
          // Start glide at t0 (when note starts) to ensure proper timing, especially for loop boundary
          // If t0 is in the future, the frequency will stay at currentFreq until t0, then glide
          if (t0 > now) {
            // Note starts in the future - maintain current freq until then
            osc.frequency.setValueAtTime(currentFreq, t0);
            osc.frequency.linearRampToValueAtTime(freq, t0 + glideTime);
          } else {
            // Note starts now or in the past - start gliding immediately
            osc.frequency.linearRampToValueAtTime(freq, now + glideTime);
          }
          
          // Update the sequencer voice to track the new note
          // IMPORTANT: Update noteEndTime to the new note's end time for proper loop boundary detection
          sequencerVoice.currentFreq = freq;
          sequencerVoice.noteEndTime = t0 + total;
          lastSequencerFreq = freq;
          
          // Don't let setTimeout clear this voice prematurely - it's still active
          // The setTimeout will only clear if it matches the old osc, which is fine
          
          // For legato notes: DON'T retrigger envelope - maintain current level
          // This is key to Serum 2 behavior - envelope only retriggers on non-legato notes
          // Maintain sustain to prevent gaps in the continuous voice
          const bassMixerGain = mixerMuted.bass ? 0 : partGain.bass;
          const sustainLevel = 0.22 * bassMixerGain;
          const release = 0.08;
          
          // Always maintain sustain for legato notes (which should be most notes in mono portamento)
          if (isLegato) {
            // Legato: maintain sustain level, don't retrigger envelope
            // FIX: Ensure we're at least at sustain level to prevent volume drops
            // Use the higher of currentGain or sustainLevel to prevent drops
            const targetGain = Math.max(currentGain, sustainLevel);
            
            gain.gain.cancelScheduledValues(now);
            // Set target gain immediately to prevent any volume drops
            gain.gain.setValueAtTime(targetGain, now);
            
            // If note starts in the future, maintain target gain until note starts
            // Then maintain sustain level throughout, release only at end
            if (t0 > now) {
              gain.gain.setValueAtTime(targetGain, t0);
            }
            gain.gain.setValueAtTime(sustainLevel, t0 + total - release);
            gain.gain.linearRampToValueAtTime(0, t0 + total);
          } else {
            // Non-legato: still maintain if in sustain to prevent gaps
            if (currentGain >= sustainLevel * 0.5) {
              // Already in sustain or decay - maintain it to prevent gaps
              // FIX: Ensure we're at least at sustain level
              const targetGain = Math.max(currentGain, sustainLevel);
              gain.gain.cancelScheduledValues(now);
              gain.gain.setValueAtTime(targetGain, now);
              gain.gain.setValueAtTime(sustainLevel, t0 + total - release);
              gain.gain.linearRampToValueAtTime(0, t0 + total);
            } else {
              // Voice was fading - bring it back to sustain to prevent gaps
              gain.gain.cancelScheduledValues(now);
              gain.gain.linearRampToValueAtTime(sustainLevel, now + 0.01);
              gain.gain.setValueAtTime(sustainLevel, t0 + total - release);
              gain.gain.linearRampToValueAtTime(0, t0 + total);
            }
          }
          
          // Schedule oscillator stop for the new note's end time
          osc.stop(t0 + total + 0.05);
          return;
        }

        // No existing active voice - create new one
        // Always start from last frequency if available (Serum 2 always glides)
        const osc = ctx.createOscillator();
        const gain = ctx.createGain();
        const distortion = ctx.createWaveShaper();

        osc.type = "sawtooth";
        
        // Always glide from last frequency to new frequency (Serum 2 portamento behavior)
        // Even for non-legato notes, there's always a glide
        if (startFreq !== freq && startFreq !== null) {
          osc.frequency.setValueAtTime(startFreq, t0);
          osc.frequency.linearRampToValueAtTime(freq, t0 + glideTime);
        } else {
          osc.frequency.setValueAtTime(freq, t0);
        }

        distortion.curve = createDistortionCurve(4);
        distortion.oversample = "2x";

        const attack = 0.02;
        const decay = 0.06;
        const bassMixerGain = mixerMuted.bass ? 0 : partGain.bass;
        const sustainLevel = 0.22 * bassMixerGain;
        const release = 0.08;
        const sustainTime = Math.max(0, total - (attack + decay + release));

        // Normal envelope for new notes (non-legato)
        gain.gain.setValueAtTime(0, t0);
        gain.gain.linearRampToValueAtTime(0.23 * bassMixerGain, t0 + attack);
        gain.gain.linearRampToValueAtTime(sustainLevel, t0 + attack + decay);
        gain.gain.setValueAtTime(sustainLevel, t0 + attack + decay + sustainTime);
        gain.gain.linearRampToValueAtTime(0, t0 + total);

        osc.connect(distortion);
        distortion.connect(gain);
        gain.connect(ctx.destination);

        osc.start(t0);
        osc.stop(t0 + total + 0.05);
        
        // Store the sequencer voice for portamento
        sequencerVoice = { osc, gain, currentFreq: freq, noteEndTime: t0 + total };
        lastSequencerFreq = freq;
        
        // Clean up when note ends, but keep last frequency for next note
        setTimeout(() => {
          if (sequencerVoice && sequencerVoice.osc === osc) {
            sequencerVoice = null;
            // Keep lastSequencerFreq for always-on portamento (Serum 2 behavior)
          }
        }, (total + 0.05) * 1000);
      }

      function recordNoteOn(mappedNote) {
        // Check the appropriate recording state based on current mode
        const currentRecState = currentMode === "arp" ? arpRecState : bassRecState;
        
        const ctx = getAudio();
        if (!ctx) return;
        const now = ctx.currentTime;
        
        if (currentMode === "arp") {
          // For arp mode, we don't record in recordNoteOn
          // Instead, the live arp's playNextNote function records the actual arp notes being played
          // This ensures we record what you hear, not just the root note
          // The live arp will start playing (via startLiveArp) and record each note it plays
          return;
        }
        
        // If we're in count-in or recStartTime is not set yet, store the note to be captured when recording starts
        // This captures notes held BEFORE recording actually starts
        if (currentRecState === "count-in" || recStartTime === null || recEndTime === null) {
          preRecordingNotes[mappedNote] = { pressTime: now };
          return;
        }
        
        // If not in recording state, don't record
        if (currentRecState !== "recording") {
          return;
        }
        
        // If note is played slightly before 1.1, carry it over to start at 1.1
        // Allow very generous tolerance (up to 100% of a step before) to capture early notes
        // This ensures notes played slightly early are always captured at beat 1.1
        let noteStartTime = now;
        if (now < recStartTime) {
          // Note played before recording start - always carry it over to start at 1.1
          // This captures notes held before recording starts
          noteStartTime = recStartTime;
        }
        
        // Don't record notes after recording end
        if (noteStartTime > recEndTime) return;

        // monophonic: close any pending notes first
        Object.keys(pendingNotes).forEach(existing => {
          recordNoteOff(existing);
        });

        // Calculate time relative to recStartTime for step calculation
        // Since we carried over early notes to recStartTime, elapsed will be 0 or positive
        const elapsedFromRecStart = noteStartTime - recStartTime;
        
        // FOOLPROOF BEAT 1.1 CAPTURE: Capture any note within the first step (1.1 to 1.2)
        // If note is within the first step from recStartTime, force it to step 0
        // This ensures beat 1.1 is ALWAYS captured, even with timing variations
        const step0Threshold = STEP_DUR; // Full first step - capture anything between 1.1 and 1.2
        
        let localStart;
        if (elapsedFromRecStart <= step0Threshold) {
          // Force to step 0 (beat 1.1) for any note in the first step
          localStart = 0;
        } else {
          // Use 16th note quantization (full resolution) to preserve all 16th note positions
          // This prevents doubling that was caused by 8th note quantization
          const stepFloat = elapsedFromRecStart / STEP_DUR;
          localStart = Math.round(stepFloat); // Snap to nearest 16th note step
        }
        
        // Clamp to valid range (shouldn't be needed with the logic above, but safety check)
        if (localStart < 0) localStart = 0;
        if (localStart >= TOTAL_STEPS) localStart = TOTAL_STEPS - 1;

        // Store quantized start step AND actual start time for precise duration calculation
        // Use noteStartTime (which may be recStartTime if note was early) for duration calc
        const globalStepNow = timeToGlobalStep(noteStartTime);
        pendingNotes[mappedNote] = { 
          startGlobalStep: globalStepNow, 
          localStart,
          actualStartTime: noteStartTime  // Use adjusted start time (carried over to 1.1 if early)
        };
      }

      function recordNoteOff(mappedNote) {
        // Check the appropriate recording state based on current mode
        const currentRecState = currentMode === "arp" ? arpRecState : bassRecState;
        
        // If key is released during count-in (before recording starts), remove from preRecordingNotes
        // We only want to capture notes that are still held when recording actually starts
        if (currentRecState === "count-in" || (recStartTime === null && currentRecState !== "recording")) {
          if (preRecordingNotes[mappedNote]) {
            delete preRecordingNotes[mappedNote];
          }
          return;
        }
        
        if (currentRecState !== "recording") return;
        if (currentMode === "arp") {
          // For arp mode, recording stops when key is released
          // The live arp will stop (via stopLiveArp) and stop recording notes
          // No need to clear intervals here as live arp handles it
          if (pendingNotes[mappedNote]) delete pendingNotes[mappedNote];
          return;
        }
        const ctx = getAudio();
        if (!ctx || recStartTime === null || recEndTime === null) return;
        const data = pendingNotes[mappedNote];
        if (!data) return;

        const now = ctx.currentTime;
        // Clamp note off time to not extend past recEndTime (bar 1.1 after 4 bars)
        const clamped = Math.max(recStartTime, Math.min(now, recEndTime));
        
        // Calculate actual duration in seconds (not quantized), but ensure it doesn't extend past loop boundary
        const actualDuration = Math.max(0, clamped - data.actualStartTime);
        
        // Only quantize the START position, preserve actual duration
        if (actualDuration > 0 && data.localStart >= 0 && data.localStart < TOTAL_STEPS) {
          // Ensure duration doesn't extend past the loop boundary (64 steps = 4 bars)
          const maxDuration = (TOTAL_STEPS - data.localStart) * STEP_DUR;
          const clampedDuration = Math.min(actualDuration, maxDuration);
          
          // Store duration as seconds (can be converted to steps when needed, but preserve precision)
          synthPattern[data.localStart] = { 
            note: mappedNote, 
            lengthSeconds: clampedDuration  // Store precise duration, clamped to loop boundary
          };
        }

        delete pendingNotes[mappedNote];
      }

      function finalizeRecording() {
        if (currentMode === "arp") {
          // Arp recording is handled by live arp's playNextNote
          // No cleanup needed here
          pendingNotes = {};
          currentRecordedNote = null;
          return;
        }
        // close any held notes at loop boundary - cut off exactly at recEndTime (bar 1.1 after 4 bars)
        const ctx = getAudio();
        if (ctx && recEndTime !== null) {
          Object.entries(pendingNotes).forEach(([note, data]) => {
            // Calculate duration from actual start time to end of recording
            // Ensure note is cut off exactly at recEndTime, not extending into next loop
            const actualDuration = Math.max(0, recEndTime - data.actualStartTime);
            
            // Only record if duration is positive and within the loop bounds
            if (actualDuration > 0 && data.localStart >= 0 && data.localStart < TOTAL_STEPS) {
              // Ensure duration doesn't extend past the loop boundary (64 steps = 4 bars)
              const maxDuration = (TOTAL_STEPS - data.localStart) * STEP_DUR;
              const clampedDuration = Math.min(actualDuration, maxDuration);
              
              synthPattern[data.localStart] = { 
                note, 
                lengthSeconds: clampedDuration  // Store precise duration, clamped to loop boundary
              };
            }
          });
        }
        pendingNotes = {};
      }

      // --- DOM: step indicator ---
      const stepContainer = document.getElementById("step-indicator");
      const stepDots = [];
      if (stepContainer) {
        for (let i = 0; i < 16; i++) {
          const dot = document.createElement("div");
          dot.className = "step-dot";
          // Mark downbeats: indices 0, 4, 8, 12 (beats 1.1, 2.1, 3.1, 4.1)
          if (i % 4 === 0) {
            dot.classList.add("downbeat");
          }
          stepContainer.appendChild(dot);
          stepDots.push(dot);
        }
      }

      // --- DOM: drums grid & controls ---
      const drumGrids = {};
      const drumSelects = {};

      function buildDrumGrid(part) {
        const gridEl = document.querySelector(`.drum-grid[data-part="${part}"]`);
        drumGrids[part] = gridEl;
        if (!gridEl) return;
        gridEl.innerHTML = "";
        // 4 rows (beats), 4 cols (1/e/&/a) = 16 steps
        for (let row = 0; row < 4; row++) {
          for (let col = 0; col < 4; col++) {
            const idx = row * 4 + col; // step index 0..15
            const cell = document.createElement("div");
            cell.className = "drum-cell";
            cell.dataset.step = idx.toString();
            cell.addEventListener("click", () => {
              const current = drumPatterns[part][idx];
              drumPatterns[part][idx] = !current;
              cell.classList.toggle("active", !current);
            });
            gridEl.appendChild(cell);
          }
        }
      }

      drumParts.forEach((part) => {
        buildDrumGrid(part);
        const sel = document.querySelector(`.drum-select[data-part="${part}"]`);
        if (sel) {
          drumSelects[part] = sel;
          sel.addEventListener("change", () => {
            const val = parseInt(sel.value || "1", 10);
            drumVariantIndex[part] = Math.max(0, Math.min(3, val - 1));
          });
        }
      });

      // Part mixer sliders and mute buttons
      const mixerParts = ["kick", "snare", "ch", "oh", "perc", "bass", "arp"];
      mixerParts.forEach((part) => {
        const slider = document.querySelector(`.mixer-slider[data-part="${part}"]`);
        const muteBtn = document.querySelector(`.mixer-mute-button[data-part="${part}"]`);
        
        if (slider) {
          // Initialize slider value (top = 100, bottom = 0 for vertical slider)
          slider.value = partGain[part] * 100;
          
          // Set accent color for consistent styling
          slider.style.accentColor = '#e0e0e0';
          
          slider.addEventListener("input", (e) => {
            partGain[part] = parseFloat(e.target.value) / 100;
          });
        }
        
        if (muteBtn) {
          // Initialize button state
          muteBtn.classList.toggle("active", mixerMuted[part]);
          
          muteBtn.addEventListener("click", () => {
            mixerMuted[part] = !mixerMuted[part];
            muteBtn.classList.toggle("active", mixerMuted[part]);
          });
        }
      });

      // --- DOM: transport + record ---
      const playBtn = document.getElementById("transport-play");
      const stopBtn = document.getElementById("transport-stop");
      const recBtn = document.getElementById("seq-record");

      if (playBtn) {
        playBtn.addEventListener("click", async () => {
          // Set button state immediately
          playBtn.classList.add("active");
          if (stopBtn) stopBtn.classList.remove("active");
          
          // Ensure audio context is initialized and resumed
          initAudioCtx();
          if (audioCtx && audioCtx.state !== "running") {
            try {
              await audioCtx.resume();
            } catch (e) {
              console.warn("Failed to resume audio context:", e);
            }
          }
          unlockIOSAudio();
          
          const ctx = getAudio();
          if (!ctx) {
            // If audio context fails, revert button state
            playBtn.classList.remove("active");
            if (stopBtn) stopBtn.classList.add("active");
            return;
          }
          
          // Load drum buffers in background - don't wait for them to start transport
          // This ensures immediate playback on first load
          loadDrumBuffers(ctx).catch(e => console.warn("Error loading drums:", e));

          // reset pattern playback if already running
          stopTransport();
          
          // Set mode-specific recStates based on whether patterns exist
          if (savedSynthPattern) {
            synthPattern = savedSynthPattern.map(step => step ? {...step} : null);
            bassRecState = "playing";
          } else {
            synthPattern = new Array(TOTAL_STEPS).fill(null);
            bassRecState = "idle";
          }
          if (savedArpPattern) {
            arpPattern = savedArpPattern.map(step => step ? {...step} : null);
            arpRecState = "playing";
          } else {
            arpPattern = new Array(TOTAL_STEPS).fill(null);
            arpRecState = "idle";
          }
          // Update global recState
          if (bassRecState === "playing" || arpRecState === "playing") {
            recState = "playing";
          } else {
            recState = "idle";
          }
          pendingNotes = {};
          preRecordingNotes = {};
          currentRecordedNote = null;
          recStartTime = null;
          recEndTime = null;
          recBtn.classList.remove("recording","looping");
          updateModeUI();

          startTransport();
        });
      }

      if (stopBtn) {
        stopBtn.addEventListener("click", async () => {
          // Set button state immediately
          if (playBtn) playBtn.classList.remove("active");
          stopBtn.classList.add("active");
          
          // Ensure audio context is initialized and resumed
          initAudioCtx();
          if (audioCtx && audioCtx.state !== "running") {
            try {
              await audioCtx.resume();
            } catch (e) {
              console.warn("Failed to resume audio context:", e);
            }
          }
          unlockIOSAudio();
          
          stopTransport();
          stopRecordingMetronome(); // Stop metronome when transport stops
          
          const hasSynthPattern = synthPattern.some(step => step !== null);
          if (hasSynthPattern) {
            savedSynthPattern = synthPattern.map(step => step ? {...step} : null);
          }
          const hasArpPattern = arpPattern.some(step => step !== null);
          if (hasArpPattern) {
            savedArpPattern = arpPattern.map(step => step ? {...step} : null);
          }
          // Set both mode-specific states to idle
          bassRecState = "idle";
          arpRecState = "idle";
          recState = "idle";
          // Arp recording is handled by live arp, no interval to clear
          pendingNotes = {};
          preRecordingNotes = {};
          currentRecordedNote = null;
          recStartTime = null;
          recEndTime = null;
          synthPattern = new Array(TOTAL_STEPS).fill(null);
          arpPattern = new Array(TOTAL_STEPS).fill(null);
          preRecordingNotes = {};
          if (recBtn) {
            recBtn.classList.remove("recording","looping");
            updateModeUI();
          }
        });
      }

      if (recBtn) {
        recBtn.addEventListener("click", async () => {
          // Check if we're trying to stop/clear the current recording
          // Only stop if we're recording/playing the SAME mode
          const isCurrentlyLooping = recBtn.classList.contains("looping");
          // Check if current mode is recording
          const currentRecState = currentMode === "arp" ? arpRecState : bassRecState;
          const isCurrentlyRecording = currentRecState === "recording" || currentRecState === "count-in";
          
          // If looping or recording the same mode, toggle off (stop)
          if ((isCurrentlyLooping || isCurrentlyRecording) && recState !== "idle") {
            // Check if we're in the same mode that's currently active
            // If button says "looping" or is recording, and we're in that mode, stop it
            // Only stop if we're actually looping/recording the current mode
            // When switching modes, updateModeUI changes button text but might keep "looping" class
            // So we need to check if the button text matches the current mode
            // Only stop if button text is exactly "looping" (meaning this mode is currently playing)
            // updateModeUI() removes "looping" class and changes text when switching modes
            const buttonText = recBtn.textContent;
            const isThisModeLooping = buttonText === "looping" && isCurrentlyLooping;
            
            // Only stop if this is the current mode's loop/recording
            if (isThisModeLooping || isCurrentlyRecording) {
              // Stop current recording if in progress
              if (isCurrentlyRecording) {
                stopRecordingMetronome();
                const ctx = getAudio();
                if (ctx) {
                  finalizeRecording();
                }
              }
            
            // Clear the pattern for the current mode only
            if (currentMode === "arp") {
              savedArpPattern = null;
              arpPattern = new Array(TOTAL_STEPS).fill(null);
              arpRecState = "idle";
            } else {
              savedSynthPattern = null;
              synthPattern = new Array(TOTAL_STEPS).fill(null);
              bassRecState = "idle";
            }
            
            // Arp recording is handled by live arp, no interval to clear
            pendingNotes = {};
            preRecordingNotes = {};
            currentRecordedNote = null;
            
            // Update button state
            recBtn.classList.remove("recording", "looping");
            updateModeUI();
            
            // Only stop transport if BOTH patterns are now empty
            const hasSynthPattern = savedSynthPattern && savedSynthPattern.some(step => step !== null);
            const hasArpPattern = savedArpPattern && savedArpPattern.some(step => step !== null);
            if (!hasSynthPattern && !hasArpPattern) {
              stopTransport();
              recState = "idle";
              recStartTime = null;
              recEndTime = null;
              preRecordingNotes = {};
            } else {
              // Keep transport running, other pattern is still playing
              // Update global recState based on remaining patterns
              if (bassRecState === "playing" || arpRecState === "playing") {
                recState = "playing";
              } else {
                recState = "idle";
              }
            }
            return;
            }
          }
          
          // If we get here, we're starting a new recording
          // Don't clear saved patterns - allow both bass and arp to play together
          // Only clear the pattern for the mode being recorded (done later when recording starts)
          
          // Ensure audio context is initialized and resumed
          initAudioCtx();
          if (audioCtx && audioCtx.state !== "running") {
            try {
              await audioCtx.resume();
            } catch (e) {
              console.warn("Failed to resume audio context:", e);
            }
          }
          unlockIOSAudio();
          
          const ctx = getAudio();
          if (!ctx) return;
          await loadDrumBuffers(ctx);

          // If transport not running, start it after a 4-beat count-in.
          if (!transportRunning) {
            const now = ctx.currentTime;
            const countInStart = now;
            const countInEnd = countInStart + 4 * BEAT_DUR;

            // transport start and record start at the same time, after count-in
            transportStartTime = countInEnd;
            transportRunning = true;

            // Start at step 0, schedule it at transportStartTime
            globalStepCounter = 0;
            nextStepTime = transportStartTime;
            lastQuarterVisual = null;

            if (!stepTimer) {
              stepTimer = setInterval(() => {
                const c = getAudio();
                if (!c || !transportRunning) return;
                const now2 = c.currentTime;
                const lookahead = 0.1;

                while (nextStepTime <= now2 + lookahead) {
                  const localStep = globalStepCounter % TOTAL_STEPS;

                  if (stepDots.length) {
                    const quarterIndex = Math.floor(localStep / 4);
                    if (quarterIndex !== lastQuarterVisual) {
                      stepDots.forEach((dot, idx) => {
                        dot.classList.toggle("active", idx === quarterIndex);
                      });
                      lastQuarterVisual = quarterIndex;
                    }
                  }

                  scheduleDrumsForStep(localStep, nextStepTime);
                  scheduleSynthForStep(localStep, nextStepTime);
                  scheduleArpForStep(localStep, nextStepTime);

                  // Increment AFTER scheduling so step 0 plays at transportStartTime
                  globalStepCounter++;
                  nextStepTime += STEP_DUR;
                }
              }, 25);
            }

            // Set button states immediately
            if (playBtn) playBtn.classList.add("active");
            if (stopBtn) stopBtn.classList.remove("active");
            
            // count-in display 4,3,2,1 with metronome clicks
            // Set mode-specific recording state
            if (currentMode === "arp") {
              arpRecState = "count-in";
            } else {
              bassRecState = "count-in";
            }
            recState = "count-in"; // Legacy global state
            recBtn.classList.add("recording");
            recBtn.classList.remove("looping");
            recBtn.textContent = "4";

            for (let i = 0; i < 4; i++) {
              const displayNum = 4 - i;
              const t = countInStart + i * BEAT_DUR;
              const delay = Math.max(0, (t - now) * 1000);
              
              // Play metronome click at 35% volume
              playMetronomeClick(t, 0.35);
              
              setTimeout(() => {
                const currentRecState = currentMode === "arp" ? arpRecState : bassRecState;
                if (currentRecState === "count-in") {
                  recBtn.textContent = displayNum.toString();
                }
              }, delay);
            }

            // start recording exactly at 1.1
            recStartTime = transportStartTime;
            recEndTime = recStartTime + LOOP_BEATS * BEAT_DUR;
            recStartGlobalStep = timeToGlobalStep(recStartTime);

            const toRecordMs = Math.max(0, (recStartTime - now) * 1000);
            setTimeout(() => {
              const currentRecState = currentMode === "arp" ? arpRecState : bassRecState;
              if (currentRecState !== "count-in") return;
              // Set mode-specific recording state
              if (currentMode === "arp") {
                arpRecState = "recording";
              } else {
                bassRecState = "recording";
              }
              recState = "recording"; // Legacy global state
              if (currentMode === "arp") {
                arpPattern = new Array(TOTAL_STEPS).fill(null);
              } else {
                synthPattern = new Array(TOTAL_STEPS).fill(null);
              }
              pendingNotes = {};
              
              // Capture any notes held before recording started
              // These should be recorded at step 0 (beat 1.1)
              // Only capture notes that are still in preRecordingNotes (user is still holding them)
              if (currentMode === "bass" && Object.keys(preRecordingNotes).length > 0) {
                const ctx = getAudio();
                if (ctx && recStartTime !== null && recEndTime !== null) {
                  Object.keys(preRecordingNotes).forEach(mappedNote => {
                    // Record the note at step 0 (beat 1.1)
                    // actualStartTime is recStartTime so duration is calculated from when recording starts
                    // This ensures the note doesn't bleed into the next loop
                    pendingNotes[mappedNote] = {
                      startGlobalStep: 0,
                      localStart: 0,
                      actualStartTime: recStartTime // Start exactly at 1.1, not when key was pressed
                    };
                  });
                }
              }
              preRecordingNotes = {};
              
              recBtn.textContent = currentMode === "arp" ? "rec arp*" : "rec bass*";
              startRecordingMetronome(recStartTime, recEndTime);
            }, toRecordMs);

            const toEndMs = Math.max(0, (recEndTime - now) * 1000);
            setTimeout(() => {
              const currentRecState = currentMode === "arp" ? arpRecState : bassRecState;
              if (currentRecState !== "recording") return;
              // Set mode-specific playing state
              if (currentMode === "arp") {
                arpRecState = "playing";
                savedArpPattern = arpPattern.map(step => step ? {...step} : null);
              } else {
                bassRecState = "playing";
                finalizeRecording();
                savedSynthPattern = synthPattern.map(step => step ? {...step} : null);
              }
              // Update global recState if either is playing
              if (bassRecState === "playing" || arpRecState === "playing") {
                recState = "playing";
              }
              stopRecordingMetronome();
              recBtn.classList.remove("recording");
              recBtn.classList.add("looping");
              recBtn.textContent = "looping";
            }, toEndMs);

          } else {
            // Transport is running: arm recording for NEXT full loop at 1.1
            const now = ctx.currentTime;
            const elapsedBeatsFloat = (now - transportStartTime) / BEAT_DUR;
            const currentLoopIndex = Math.floor(elapsedBeatsFloat / LOOP_BEATS);
            const recordStartLoopIndex = currentLoopIndex + 1;
            const recordStartBeatGlobal = recordStartLoopIndex * LOOP_BEATS; // beat index from transportStart

            const recStart = transportStartTime + recordStartBeatGlobal * BEAT_DUR;
            loopDuration = LOOP_BEATS * BEAT_DUR; // 4 bars = 16 beats
            const recEnd = recStart + loopDuration; // End exactly at next 1.1

            // count-in over last 4 beats of current loop (4,3,2,1) with metronome clicks
            // Set mode-specific recording state
            if (currentMode === "arp") {
              arpRecState = "count-in";
            } else {
              bassRecState = "count-in";
            }
            recState = "count-in"; // Legacy global state
            recBtn.classList.add("recording");
            recBtn.classList.remove("looping");
            recBtn.textContent = "4";

            for (let i = 0; i < 4; i++) {
              const beatIndex = recordStartBeatGlobal - (4 - i); // beats before recStart
              const t = transportStartTime + beatIndex * BEAT_DUR;
              const displayNum = 4 - i;
              const delay = Math.max(0, (t - now) * 1000);
              
              // Play metronome click at 35% volume
              playMetronomeClick(t, 0.35);
              
              setTimeout(() => {
                const currentRecState = currentMode === "arp" ? arpRecState : bassRecState;
                if (currentRecState === "count-in") {
                  recBtn.textContent = displayNum.toString();
                }
              }, delay);
            }

            recStartTime = recStart;
            recEndTime = recEnd;
            recStartGlobalStep = recordStartBeatGlobal * 4; // 4 steps per beat

            const toRecordMs = Math.max(0, (recStartTime - now) * 1000);
            setTimeout(() => {
              const currentRecState = currentMode === "arp" ? arpRecState : bassRecState;
              if (currentRecState !== "count-in") return;
              // Set mode-specific recording state
              if (currentMode === "arp") {
                arpRecState = "recording";
              } else {
                bassRecState = "recording";
              }
              recState = "recording"; // Legacy global state
              if (currentMode === "arp") {
                arpPattern = new Array(TOTAL_STEPS).fill(null);
              } else {
                synthPattern = new Array(TOTAL_STEPS).fill(null);
              }
              pendingNotes = {};
              
              // Capture any notes held before recording started
              // These should be recorded at step 0 (beat 1.1)
              // Only capture notes that are still in preRecordingNotes (user is still holding them)
              if (currentMode === "bass" && Object.keys(preRecordingNotes).length > 0) {
                const ctx = getAudio();
                if (ctx && recStartTime !== null && recEndTime !== null) {
                  Object.keys(preRecordingNotes).forEach(mappedNote => {
                    // Record the note at step 0 (beat 1.1)
                    // actualStartTime is recStartTime so duration is calculated from when recording starts
                    // This ensures the note doesn't bleed into the next loop
                    pendingNotes[mappedNote] = {
                      startGlobalStep: 0,
                      localStart: 0,
                      actualStartTime: recStartTime // Start exactly at 1.1, not when key was pressed
                    };
                  });
                }
              }
              preRecordingNotes = {};
              
              recBtn.textContent = currentMode === "arp" ? "rec arp*" : "rec bass*";
              startRecordingMetronome(recStartTime, recEndTime);
            }, toRecordMs);

            const toEndMs = Math.max(0, (recEndTime - now) * 1000);
            setTimeout(() => {
              const currentRecState = currentMode === "arp" ? arpRecState : bassRecState;
              if (currentRecState !== "recording") return;
              // Set mode-specific playing state
              if (currentMode === "arp") {
                arpRecState = "playing";
                savedArpPattern = arpPattern.map(step => step ? {...step} : null);
              } else {
                bassRecState = "playing";
                finalizeRecording();
                savedSynthPattern = synthPattern.map(step => step ? {...step} : null);
              }
              // Update global recState if either is playing
              if (bassRecState === "playing" || arpRecState === "playing") {
                recState = "playing";
              }
              stopRecordingMetronome();
              recBtn.classList.remove("recording");
              recBtn.classList.add("looping");
              recBtn.textContent = "looping";
            }, toEndMs);
          }
        });
      }

      // --- PIANO / POINTER INPUT & RECORD HOOKS ---
      const piano = document.querySelector(".piano");
      const keys = document.querySelectorAll(".key[data-note]");
      if (!piano || !keys.length) return;

      let pointerDown = false;
      let activeTouchId = null;
      let activeKeyEl = null;

      function setActiveKey(newKey) {
        if (activeKeyEl === newKey) return;
        if (activeKeyEl) {
          activeKeyEl.classList.remove("is-down");
        }
        activeKeyEl = newKey;
        if (activeKeyEl) {
          activeKeyEl.classList.add("is-down");
        }
      }

      function getKeyFromTarget(target) {
        if (!target) return null;
        if (target.classList && target.classList.contains("key") && target.dataset.note) {
          return target;
        }
        return target.closest ? target.closest(".key[data-note]") : null;
      }

      // Mouse
      keys.forEach((key) => {
        key.addEventListener("mousedown", (e) => {
          e.preventDefault();
          pointerDown = true;
          const rawNote = key.getAttribute("data-note");
          if (!rawNote) return;
          const mapped = scaleMap[rawNote] || rawNote;
          currentRecordedNote = mapped;

          setActiveKey(key);
          // Check if current mode is recording or in count-in
          // Allow recording during count-in to capture notes held before recording starts
          const currentRecState = currentMode === "arp" ? arpRecState : bassRecState;
          if (currentRecState === "recording" || currentRecState === "count-in") {
            recordNoteOn(mapped);
          }
          startOrGlideToNote(rawNote);
        });
      });

      window.addEventListener("mouseup", () => {
        if (!pointerDown) return;
        pointerDown = false;
        const currentRecState = currentMode === "arp" ? arpRecState : bassRecState;
        // Call recordNoteOff for both recording and count-in states
        // This handles notes held before recording starts
        if ((currentRecState === "recording" || currentRecState === "count-in") && currentRecordedNote) {
          recordNoteOff(currentRecordedNote);
        }
        currentRecordedNote = null;
        setActiveKey(null);
        stopCurrentVoice();
      });

      piano.addEventListener("mousemove", (e) => {
        if (!pointerDown) return;
        const el = document.elementFromPoint(e.clientX, e.clientY);
        const key = getKeyFromTarget(el);
        if (!key) return;
        const rawNote = key.getAttribute("data-note");
        if (!rawNote) return;
        const mapped = scaleMap[rawNote] || rawNote;

        if (mapped !== currentRecordedNote) {
          const currentRecState = currentMode === "arp" ? arpRecState : bassRecState;
          if (currentRecState === "recording" && currentRecordedNote) {
            recordNoteOff(currentRecordedNote);
          }
          // Allow recording during count-in to capture notes held before recording starts
          if (currentRecState === "recording" || currentRecState === "count-in") {
            recordNoteOn(mapped);
          }
          currentRecordedNote = mapped;
        }

        setActiveKey(key);
        startOrGlideToNote(rawNote);
      });

      // Touch
      piano.addEventListener("touchstart", (e) => {
        e.preventDefault();
        if (activeTouchId !== null) return;
        const touch = e.changedTouches[0];
        activeTouchId = touch.identifier;
        pointerDown = true;
        const el = document.elementFromPoint(touch.clientX, touch.clientY);
        const key = getKeyFromTarget(el);
        if (!key) return;
        const rawNote = key.getAttribute("data-note");
        if (!rawNote) return;
        const mapped = scaleMap[rawNote] || rawNote;

        currentRecordedNote = mapped;
        setActiveKey(key);
        // Allow recording during count-in to capture notes held before recording starts
        const currentRecState = currentMode === "arp" ? arpRecState : bassRecState;
        if (recState === "recording" || currentRecState === "count-in") {
          recordNoteOn(mapped);
        }
        startOrGlideToNote(rawNote);
      }, { passive: false });

      piano.addEventListener("touchmove", (e) => {
        if (activeTouchId === null) return;
        const touch = Array.from(e.changedTouches).find(t => t.identifier === activeTouchId);
        if (!touch) return;
        const el = document.elementFromPoint(touch.clientX, touch.clientY);
        const key = getKeyFromTarget(el);
        if (!key) return;
        const rawNote = key.getAttribute("data-note");
        if (!rawNote) return;
        const mapped = scaleMap[rawNote] || rawNote;

        if (mapped !== currentRecordedNote) {
          const currentRecState = currentMode === "arp" ? arpRecState : bassRecState;
          if (currentRecState === "recording" && currentRecordedNote) {
            recordNoteOff(currentRecordedNote);
          }
          // Allow recording during count-in to capture notes held before recording starts
          if (currentRecState === "recording" || currentRecState === "count-in") {
            recordNoteOn(mapped);
          }
          currentRecordedNote = mapped;
        }

        setActiveKey(key);
        startOrGlideToNote(rawNote);
      }, { passive: false });

      function endTouch(e) {
        if (activeTouchId === null) return;
        const touch = Array.from(e.changedTouches).find(t => t.identifier === activeTouchId);
        if (!touch) return;
        activeTouchId = null;
        pointerDown = false;
        const currentRecState = currentMode === "arp" ? arpRecState : bassRecState;
        // Call recordNoteOff for both recording and count-in states
        // This handles notes held before recording starts
        if ((currentRecState === "recording" || currentRecState === "count-in") && currentRecordedNote) {
          recordNoteOff(currentRecordedNote);
        }
        currentRecordedNote = null;
        setActiveKey(null);
        stopCurrentVoice();
      }

      piano.addEventListener("touchend", endTouch, { passive: false });
      piano.addEventListener("touchcancel", endTouch, { passive: false });

      // --- KEYBOARD PIANO ROLL SUPPORT (Ableton-style) ---
      // Keyboard mapping: Ableton-style layout
      // White keys: A, S, D, F, G, H, J, K (C, D, E, F, G, A, B, C)
      // Black keys: W, E, T, Y, U (C#, D#, F#, G#, A#)
      const keyboardMap = {
        'a': 'C1',
        'w': 'C#1',
        's': 'D1',
        'e': 'D#1',
        'd': 'E1',
        'f': 'F1',
        't': 'F#1',
        'g': 'G1',
        'y': 'G#1',
        'h': 'A1',
        'u': 'A#1',
        'j': 'B1',
        'k': 'C2'
      };

      // Track currently pressed keyboard keys to avoid retriggering
      const pressedKeys = new Set();
      // Track which raw note is currently playing (for monophonic behavior)
      let currentKeyboardRawNote = null;

      // Helper to get the visual key element for a note
      function getKeyElementForNote(note) {
        return document.querySelector(`.key[data-note="${note}"]`);
      }

      function handleKeyboardNoteOn(key) {
        const rawNote = keyboardMap[key.toLowerCase()];
        if (!rawNote) return;
        
        // Don't retrigger if key is already pressed
        if (pressedKeys.has(key.toLowerCase())) return;
        pressedKeys.add(key.toLowerCase());

        const mapped = scaleMap[rawNote] || rawNote;
        
        // Update current note - this is the note we're playing now
        const previousNote = currentKeyboardRawNote;
        currentKeyboardRawNote = rawNote;

        // Update visual key state
        const keyEl = getKeyElementForNote(rawNote);
        if (keyEl) {
          keyEl.classList.add("is-down");
        }

        // Handle recording - for bass mode, need to end previous note if different
        const currentRecState = currentMode === "arp" ? arpRecState : bassRecState;
        if (currentRecState === "recording" || currentRecState === "count-in") {
          // For bass mode, if we had a previous note and it's different, end it first (monophonic)
          if (currentMode !== "arp" && previousNote && previousNote !== rawNote) {
            const prevMapped = scaleMap[previousNote] || previousNote;
            recordNoteOff(prevMapped);
          }
          recordNoteOn(mapped);
        }

        // Play the note based on current mode
        startOrGlideToNote(rawNote);
      }

      function handleKeyboardNoteOff(key) {
        const rawNote = keyboardMap[key.toLowerCase()];
        if (!rawNote) return;
        
        // Only handle if this key was actually pressed
        if (!pressedKeys.has(key.toLowerCase())) return;
        pressedKeys.delete(key.toLowerCase());

        const mapped = scaleMap[rawNote] || rawNote;

        // Update visual key state
        const keyEl = getKeyElementForNote(rawNote);
        if (keyEl) {
          keyEl.classList.remove("is-down");
        }

        // Only stop voice and handle recording if this is the currently playing note
        if (currentKeyboardRawNote === rawNote) {
          // Handle recording
          const currentRecState = currentMode === "arp" ? arpRecState : bassRecState;
          if (currentRecState === "recording" || currentRecState === "count-in") {
            recordNoteOff(mapped);
          }

          // Check if there are any other keys still pressed
          let nextNote = null;
          for (const pressedKey of pressedKeys) {
            const note = keyboardMap[pressedKey.toLowerCase()];
            if (note) {
              nextNote = note;
              break; // Use first found pressed key's note
            }
          }

          if (nextNote) {
            // Another key is still pressed - glide to that note
            currentKeyboardRawNote = nextNote;
            const nextMapped = scaleMap[nextNote] || nextNote;
            
            // Handle recording for the new note
            const currentRecState = currentMode === "arp" ? arpRecState : bassRecState;
            if (currentRecState === "recording" || currentRecState === "count-in") {
              recordNoteOn(nextMapped);
            }
            
            startOrGlideToNote(nextNote);
          } else {
            // No other keys pressed - stop the voice
            currentKeyboardRawNote = null;
            stopCurrentVoice();
          }
        }
      }

      // Keyboard event listeners
      document.addEventListener("keydown", (e) => {
        // Don't interfere with typing in inputs, textareas, or when modifier keys are held
        // Also allow Escape key to pass through for tooltip closing
        if (e.target.tagName === 'INPUT' || e.target.tagName === 'TEXTAREA' || 
            e.ctrlKey || e.metaKey || e.altKey || e.key === "Escape") {
          return;
        }

        const key = e.key.toLowerCase();
        
        // Octave controls: Z = down, X = up
        if (key === 'z' || key === 'x') {
          e.preventDefault();
          if (key === 'x') {
            // Octave up
            if (currentMode === "arp") {
              arpOctaveOffset = Math.min(arpOctaveOffset + 1, 5); // Arp can go higher
            } else {
              octaveOffset = Math.min(octaveOffset + 1, 2); // Limit to +2 octaves for bass
            }
          } else if (key === 'z') {
            // Octave down
            if (currentMode === "arp") {
              arpOctaveOffset = Math.max(arpOctaveOffset - 1, 0); // Arp can't go below base
            } else {
              octaveOffset = Math.max(octaveOffset - 1, -2); // Limit to -2 octaves for bass
            }
          }
          return;
        }
        
        if (keyboardMap[key]) {
          e.preventDefault();
          handleKeyboardNoteOn(key);
        }
      });

      document.addEventListener("keyup", (e) => {
        // Don't interfere with typing in inputs or textareas
        if (e.target.tagName === 'INPUT' || e.target.tagName === 'TEXTAREA') {
          return;
        }

        const key = e.key.toLowerCase();
        if (keyboardMap[key]) {
          e.preventDefault();
          handleKeyboardNoteOff(key);
        }
      });

      // Clear all pressed keys if focus is lost (prevents stuck notes)
      window.addEventListener("blur", () => {
        pressedKeys.forEach(key => {
          const rawNote = keyboardMap[key.toLowerCase()];
          if (rawNote) {
            const keyEl = getKeyElementForNote(rawNote);
            if (keyEl) {
              keyEl.classList.remove("is-down");
            }
          }
        });
        pressedKeys.clear();
        if (currentKeyboardRawNote) {
          const mapped = scaleMap[currentKeyboardRawNote] || currentKeyboardRawNote;
          const currentRecState = currentMode === "arp" ? arpRecState : bassRecState;
          if ((currentRecState === "recording" || currentRecState === "count-in") && mapped) {
            recordNoteOff(mapped);
          }
          currentKeyboardRawNote = null;
          stopCurrentVoice();
        }
      });
    });

    // Drunk-vision cursor trail
    document.addEventListener("mousemove", (e) => {
      const trail = document.createElement("div");
      trail.className = "cursor-trail";

      trail.style.left = e.clientX + "px";
      trail.style.top = e.clientY + "px";

      const scale = 0.9 + Math.random() * 0.4;
      trail.style.width = 14 * scale + "px";
      trail.style.height = 14 * scale + "px";
      trail.style.background = `rgba(0, 0, 0, ${0.08 + Math.random() * 0.07})`;
      trail.style.filter = "blur(" + (4 + Math.random() * 3) + "px)";

      document.body.appendChild(trail);
      setTimeout(() => trail.remove(), 750);
    });

    // Tooltip functionality
    document.addEventListener("DOMContentLoaded", () => {
      const tooltipButton = document.getElementById("tooltip-button");
      const tooltipDialogue = document.getElementById("tooltip-dialogue");
      const tooltipOverlay = document.getElementById("tooltip-overlay");
      const tooltipClose = document.getElementById("tooltip-close");

      function openTooltip() {
        tooltipDialogue.classList.add("active");
        tooltipOverlay.classList.add("active");
      }

      function closeTooltip() {
        tooltipDialogue.classList.remove("active");
        tooltipOverlay.classList.remove("active");
      }

      if (tooltipButton) {
        tooltipButton.addEventListener("click", (e) => {
          e.preventDefault();
          openTooltip();
        });
      }

      if (tooltipClose) {
        tooltipClose.addEventListener("click", (e) => {
          e.preventDefault();
          closeTooltip();
        });
      }

      if (tooltipOverlay) {
        tooltipOverlay.addEventListener("click", (e) => {
          e.preventDefault();
          closeTooltip();
        });
      }

      // Close on Escape key
      document.addEventListener("keydown", (e) => {
        if (e.key === "Escape" && tooltipDialogue.classList.contains("active")) {
          closeTooltip();
        }
      });
    });

  </script>

</body>
</html>